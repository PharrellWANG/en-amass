{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to English Amassing\n\u00b6\n\n\nThis is the place where I take notes about English learning. :D",
            "title": "Home"
        },
        {
            "location": "/#welcome-to-english-amassing",
            "text": "This is the place where I take notes about English learning. :D",
            "title": "Welcome to English Amassing"
        },
        {
            "location": "/2018/04/",
            "text": "April 29, 2018\n\u00b6\n\n\nTED Talk - Stuart Russell: 3 Principals for creating safer AI\n\u00b6\n\n\nVideo\n\u00b6\n\n\nStuart Russell: 3 Principals for creating safer AI\n\n\nNotes\n\u00b6\n\n\n\n\nHoly cow: This is just an exclamation of surprise. (Click \nhere\n for more)\n\n\n\n\n1. Holy cow! Did you see that?\n2. Holy cow moment\n\n\n\n\n\n\nTechnologies that are coming down the pike: If something comes down the pike, it starts to happen or to become available.\n\n\n\n\n1. You should take this job offer\u2014who knows when another will come down the pike?\n2. That pitcher is the first young star to come down the pike for the team in many years.\n\n\n\n\nHere's an excerpt from the talk\n: Well, the real world is much bigger, much more complicated than the Go board. It's a lot less visible, but it's still a decision problem. And if we think about some of the technologies that are coming down the pike ... Noriko [Arai] mentioned that reading is not yet happening in machines, at least with understanding. But that will happen, and when that happens, very soon afterwards, machines will have read everything that the human race has ever written. And that will enable machines, along with the ability to look further ahead than humans can, as we've already seen in Go, if they also have access to more information, they'll be able to make better decisions in the real world than we can. So is that a good thing? Well, I hope so.\n\n\n\n\nQuote\n\n\nEven if we could keep the machines in a subservient position, for instance, by turning off the power at strategic moments, we should, as a species, feel greatly humbled. -- Alan Turing in 1951\n\n\n\n\n\n\nin dire straits: in a very bad situation that is difficult to fix.\n\n\n\n\nThese kids are in dire straits, and the schools are doing nothing to help them!\n\n\n\n\n\n\nexistential: of, related to, or affirming existence.\n\n\n\n\nIn fact, you can see the existential sadness in their eyes.\n\n\n\n\n\n\n\n\ngorilla: \u5927\u7329\u7329\n\n\n\n\n\n\nnail down the problem a bit more: identify the problem more precisely.\n\n\n\n\n\n\n\n\nQuote\n\n\nWe had better be quite sure that the purpose put into the machine is the purpose which we really desire. -- Norbert Wiener in 1960\n\n\n\n\n\n\n\n\nso to speak:\n\n\n\n\nthis is one way to say it. Used to suggest that some people may not think this is a good way to say something.\n\n\n\n\nI am a writer, so to speak.\n\n\n\n\n\n\na metaphor for something, used to explain that what you are saying is not to be understood exactly as stated.\n\n\n\n\nIn that relationship it's very much Lorna who wears the trousers, so to speak (= Lorna makes all the important decisions).\n\n\n\n\n\n\n\n\ndie in misery and starvation: \u6b7b\u4e8e\u75db\u82e6\u548c\u9965\u997f\n\n\n\n\n\n\noutwit: to defeat sb/sth or gain an advantage over them by doing sth clever. (outsmart)\n\n\n\n\n\n\nSomehow, he always manages to outwit his opponents.\n\n\n\n\n*nastiness\n\n\nExcerpt\n: if we look at his actions, he took an action that lost the game. That doesn't mean he wanted to lose.\n\n\nExcerpt\n: There's also a very strong economic incentive to get this right. So imagine your domestic robot's at home. You're late from work again and the robot has to feed the kids, and the kids are hungry and there's nothing in the fridge. And the robot sees the cat. And the robot hasn't quite learned the human value function properly, so it doesn't understand the sentimental value of the cat outweighs the nutritional value of the cat. So then what happens? Well, it happens like this: \"Deranged robot cooks kitty for family dinner.\" That one incident would be the end of the domestic robot industry. So there's a huge incentive to get this right long before we reach superintelligent machines.\n\n\n\n\n\n\nprovably beneficial machines\n\n\n\n\n\n\naltruistic: showing a disinterested and selfless concern for the well-being of others; unselfish.\n\n\n\n\n\n\nIt was an entirely altruistic act/behaviour.\n\n\n\n\n\n\n\n\ncomply\n\n\n\n\n\n\nfive-year-old",
            "title": "April"
        },
        {
            "location": "/2018/04/#april-29-2018",
            "text": "",
            "title": "April 29, 2018"
        },
        {
            "location": "/2018/04/#ted-talk-stuart-russell-3-principals-for-creating-safer-ai",
            "text": "",
            "title": "TED Talk - Stuart Russell: 3 Principals for creating safer AI"
        },
        {
            "location": "/2018/04/#video",
            "text": "Stuart Russell: 3 Principals for creating safer AI",
            "title": "Video"
        },
        {
            "location": "/2018/04/#notes",
            "text": "Holy cow: This is just an exclamation of surprise. (Click  here  for more)   1. Holy cow! Did you see that?\n2. Holy cow moment   Technologies that are coming down the pike: If something comes down the pike, it starts to happen or to become available.   1. You should take this job offer\u2014who knows when another will come down the pike?\n2. That pitcher is the first young star to come down the pike for the team in many years.  Here's an excerpt from the talk : Well, the real world is much bigger, much more complicated than the Go board. It's a lot less visible, but it's still a decision problem. And if we think about some of the technologies that are coming down the pike ... Noriko [Arai] mentioned that reading is not yet happening in machines, at least with understanding. But that will happen, and when that happens, very soon afterwards, machines will have read everything that the human race has ever written. And that will enable machines, along with the ability to look further ahead than humans can, as we've already seen in Go, if they also have access to more information, they'll be able to make better decisions in the real world than we can. So is that a good thing? Well, I hope so.   Quote  Even if we could keep the machines in a subservient position, for instance, by turning off the power at strategic moments, we should, as a species, feel greatly humbled. -- Alan Turing in 1951    in dire straits: in a very bad situation that is difficult to fix.   These kids are in dire straits, and the schools are doing nothing to help them!   existential: of, related to, or affirming existence.   In fact, you can see the existential sadness in their eyes.    gorilla: \u5927\u7329\u7329    nail down the problem a bit more: identify the problem more precisely.     Quote  We had better be quite sure that the purpose put into the machine is the purpose which we really desire. -- Norbert Wiener in 1960     so to speak:   this is one way to say it. Used to suggest that some people may not think this is a good way to say something.   I am a writer, so to speak.   a metaphor for something, used to explain that what you are saying is not to be understood exactly as stated.   In that relationship it's very much Lorna who wears the trousers, so to speak (= Lorna makes all the important decisions).    die in misery and starvation: \u6b7b\u4e8e\u75db\u82e6\u548c\u9965\u997f    outwit: to defeat sb/sth or gain an advantage over them by doing sth clever. (outsmart)    Somehow, he always manages to outwit his opponents.  *nastiness  Excerpt : if we look at his actions, he took an action that lost the game. That doesn't mean he wanted to lose.  Excerpt : There's also a very strong economic incentive to get this right. So imagine your domestic robot's at home. You're late from work again and the robot has to feed the kids, and the kids are hungry and there's nothing in the fridge. And the robot sees the cat. And the robot hasn't quite learned the human value function properly, so it doesn't understand the sentimental value of the cat outweighs the nutritional value of the cat. So then what happens? Well, it happens like this: \"Deranged robot cooks kitty for family dinner.\" That one incident would be the end of the domestic robot industry. So there's a huge incentive to get this right long before we reach superintelligent machines.    provably beneficial machines    altruistic: showing a disinterested and selfless concern for the well-being of others; unselfish.    It was an entirely altruistic act/behaviour.    comply    five-year-old",
            "title": "Notes"
        },
        {
            "location": "/2018/05/",
            "text": "May 4, 2018\n\u00b6\n\n\nQuote of the Day\n\u00b6\n\n\n\n\nThe next frontiers of scientific discovery will be pioneered by those who can transcend the traditional boundaries of science. -- Eric Schmidt, Former CEO of Google\n\n\n\n\nTED Talk - Nick Bostrom (TED 2015): What happens when our computers get smarter than we are?\n\u00b6\n\n\nVideo\n\u00b6\n\n\nNick Bostrom (TED 2015): What happens when our computers get smarter than we are?\n\n\nNotes\n\u00b6\n\n\n\n\nIt's a curious shape for a normal condition: \ncurious\n here means \nstrange and unusual\n.\n\n\n\n\nIt was curious that she didn't tell anyone.\nThere was a curious mixture of people in the audience.\nIt was a curious feeling, as though we were floating on the air.\n\n\n\n\n\n\nas thought: same as \nas if\n, used to describe how a situation seems to be.\n\n\n\n\nThey stared at me as though I was crazy.\nShe looked as though she'd had some bad news.\nShe behaved as though he wasn't there.\nI felt as though I'd been lying in the sun for hours.\n\n\n\n\nSentences\n\u00b6\n\n\n\n\nSo a bunch of relatively minor changes take us from Kanzi to Witten, from broken-off tree branches to intercontinental ballistic missiles:\n\n\n\n\nbreak off: if part of something breaks off or if you break it off, it comes off or is removed by force. \nbroken-off tree branches\n means those tree branches that has been removed by force.\n\n\nintercontinental ballistic missiles(ICBM): \u6d32\u9645\u5f39\u9053\u5bfc\u5f39. In this sentence, that means, we human species have evolved a lot due to a bunch of relatively minor changes which has made us more intelligent, and     \nthe more intelligent we\n have created intercontinental ballistic missiles, we no longer use broken-off tree branches like ancient ancestors.\n\n\nTranscripts\n\u00b6\n\n\n00:12\nI work with a bunch of mathematicians, philosophers and computer scientists, and we sit around and think about the future of machine intelligence, among other things. Some people think that some of these things are sort of science fiction-y, far out there, crazy. But I like to say, okay, let's look at the modern human condition. (Laughter) This is the normal way for things to be.\n\n\n00:41\nBut if we think about it, we are actually recently arrived guests on this planet, the human species. Think about if Earth was created one year ago, the human species, then, would be 10 minutes old. The industrial era started two seconds ago. Another way to look at this is to think of world GDP over the last 10,000 years, I've actually taken the trouble to plot this for you in a graph. It looks like this. (Laughter) It's a curious shape for a normal condition. I sure wouldn't want to sit on it. (Laughter)\n\n\n01:19\nLet's ask ourselves, what is the cause of this current anomaly? Some people would say it's technology. Now it's true, technology has accumulated through human history, and right now, technology advances extremely rapidly -- that is the proximate cause, that's why we are currently so very productive. But I like to think back further to the ultimate cause.\n\n\n01:45\nLook at these two highly distinguished gentlemen: We have Kanzi -- he's mastered 200 lexical tokens, an incredible feat. And Ed Witten unleashed the second superstring revolution. If we look under the hood, this is what we find: basically the same thing. One is a little larger, it maybe also has a few tricks in the exact way it's wired. These invisible differences cannot be too complicated, however, because there have only been 250,000 generations since our last common ancestor. We know that complicated mechanisms take a long time to evolve. So a bunch of relatively minor changes take us from Kanzi to Witten, from broken-off tree branches to intercontinental ballistic missiles.\n\n\n02:32\nSo this then seems pretty obvious that everything we've achieved, and everything we care about, depends crucially on some relatively minor changes that made the human mind. And the corollary, of course, is that any further changes that could significantly change the substrate of thinking could have potentially enormous consequences.\n\n\n02:56\nSome of my colleagues think we're on the verge of something that could cause a profound change in that substrate, and that is machine superintelligence. Artificial intelligence used to be about putting commands in a box. You would have human programmers that would painstakingly handcraft knowledge items. You build up these expert systems, and they were kind of useful for some purposes, but they were very brittle, you couldn't scale them. Basically, you got out only what you put in. But since then, a paradigm shift has taken place in the field of artificial intelligence.\n\n\n03:30\nToday, the action is really around machine learning. So rather than handcrafting knowledge representations and features, we create algorithms that learn, often from raw perceptual data. Basically the same thing that the human infant does. The result is A.I. that is not limited to one domain -- the same system can learn to translate between any pairs of languages, or learn to play any computer game on the Atari console. Now of course, A.I. is still nowhere near having the same powerful, cross-domain ability to learn and plan as a human being has. The cortex still has some algorithmic tricks that we don't yet know how to match in machines.\n\n\n04:19\nSo the question is, how far are we from being able to match those tricks? A couple of years ago, we did a survey of some of the world's leading A.I. experts, to see what they think, and one of the questions we asked was, \"By which year do you think there is a 50 percent probability that we will have achieved human-level machine intelligence?\" We defined human-level here as the ability to perform almost any job at least as well as an adult human, so real human-level, not just within some limited domain. And the median answer was 2040 or 2050, depending on precisely which group of experts we asked. Now, it could happen much, much later, or sooner, the truth is nobody really knows.\n\n\n05:05\nWhat we do know is that the ultimate limit to information processing in a machine substrate lies far outside the limits in biological tissue. This comes down to physics. A biological neuron fires, maybe, at 200 hertz, 200 times a second. But even a present-day transistor operates at the Gigahertz. Neurons propagate slowly in axons, 100 meters per second, tops. But in computers, signals can travel at the speed of light. There are also size limitations, like a human brain has to fit inside a cranium, but a computer can be the size of a warehouse or larger. So the potential for superintelligence lies dormant in matter, much like the power of the atom lay dormant throughout human history, patiently waiting there until 1945. In this century, scientists may learn to awaken the power of artificial intelligence. And I think we might then see an intelligence explosion.\n\n\n06:10\nNow most people, when they think about what is smart and what is dumb, I think have in mind a picture roughly like this. So at one end we have the village idiot, and then far over at the other side we have Ed Witten, or Albert Einstein, or whoever your favorite guru is. But I think that from the point of view of artificial intelligence, the true picture is actually probably more like this: AI starts out at this point here, at zero intelligence, and then, after many, many years of really hard work, maybe eventually we get to mouse-level artificial intelligence, something that can navigate cluttered environments as well as a mouse can. And then, after many, many more years of really hard work, lots of investment, maybe eventually we get to chimpanzee-level artificial intelligence. And then, after even more years of really, really hard work, we get to village idiot artificial intelligence. And a few moments later, we are beyond Ed Witten. The train doesn't stop at Humanville Station. It's likely, rather, to swoosh right by.\n\n\n07:14\nNow this has profound implications, particularly when it comes to questions of power. For example, chimpanzees are strong -- pound for pound, a chimpanzee is about twice as strong as a fit human male. And yet, the fate of Kanzi and his pals depends a lot more on what we humans do than on what the chimpanzees do themselves. Once there is superintelligence, the fate of humanity may depend on what the superintelligence does. Think about it: Machine intelligence is the last invention that humanity will ever need to make. Machines will then be better at inventing than we are, and they'll be doing so on digital timescales. What this means is basically a telescoping of the future. Think of all the crazy technologies that you could have imagined maybe humans could have developed in the fullness of time: cures for aging, space colonization, self-replicating nanobots or uploading of minds into computers, all kinds of science fiction-y stuff that's nevertheless consistent with the laws of physics. All of this superintelligence could develop, and possibly quite rapidly.\n\n\n08:24\nNow, a superintelligence with such technological maturity would be extremely powerful, and at least in some scenarios, it would be able to get what it wants. We would then have a future that would be shaped by the preferences of this A.I. Now a good question is, what are those preferences? Here it gets trickier. To make any headway with this, we must first of all avoid anthropomorphizing. And this is ironic because every newspaper article about the future of A.I. has a picture of this: So I think what we need to do is to conceive of the issue more abstractly, not in terms of vivid Hollywood scenarios.\n\n\n09:09\nWe need to think of intelligence as an optimization process, a process that steers the future into a particular set of configurations. A superintelligence is a really strong optimization process. It's extremely good at using available means to achieve a state in which its goal is realized. This means that there is no necessary connection between being highly intelligent in this sense, and having an objective that we humans would find worthwhile or meaningful.\n\n\n09:39\nSuppose we give an A.I. the goal to make humans smile. When the A.I. is weak, it performs useful or amusing actions that cause its user to smile. When the A.I. becomes superintelligent, it realizes that there is a more effective way to achieve this goal: take control of the world and stick electrodes into the facial muscles of humans to cause constant, beaming grins. Another example, suppose we give A.I. the goal to solve a difficult mathematical problem. When the A.I. becomes superintelligent, it realizes that the most effective way to get the solution to this problem is by transforming the planet into a giant computer, so as to increase its thinking capacity. And notice that this gives the A.I.s an instrumental reason to do things to us that we might not approve of. Human beings in this model are threats, we could prevent the mathematical problem from being solved.\n\n\n10:29\nOf course, perceivably things won't go wrong in these particular ways; these are cartoon examples. But the general point here is important: if you create a really powerful optimization process to maximize for objective x, you better make sure that your definition of x incorporates everything you care about. This is a lesson that's also taught in many a myth. King Midas wishes that everything he touches be turned into gold. He touches his daughter, she turns into gold. He touches his food, it turns into gold. This could become practically relevant, not just as a metaphor for greed, but as an illustration of what happens if you create a powerful optimization process and give it misconceived or poorly specified goals.\n\n\n11:16\nNow you might say, if a computer starts sticking electrodes into people's faces, we'd just shut it off. A, this is not necessarily so easy to do if we've grown dependent on the system -- like, where is the off switch to the Internet? B, why haven't the chimpanzees flicked the off switch to humanity, or the Neanderthals? They certainly had reasons. We have an off switch, for example, right here. (Choking) The reason is that we are an intelligent adversary; we can anticipate threats and plan around them. But so could a superintelligent agent, and it would be much better at that than we are. The point is, we should not be confident that we have this under control here.\n\n\n12:04\nAnd we could try to make our job a little bit easier by, say, putting the A.I. in a box, like a secure software environment, a virtual reality simulation from which it cannot escape. But how confident can we be that the A.I. couldn't find a bug. Given that merely human hackers find bugs all the time, I'd say, probably not very confident. So we disconnect the ethernet cable to create an air gap, but again, like merely human hackers routinely transgress air gaps using social engineering. Right now, as I speak, I'm sure there is some employee out there somewhere who has been talked into handing out her account details by somebody claiming to be from the I.T. department.\n\n\n12:46\nMore creative scenarios are also possible, like if you're the A.I., you can imagine wiggling electrodes around in your internal circuitry to create radio waves that you can use to communicate. Or maybe you could pretend to malfunction, and then when the programmers open you up to see what went wrong with you, they look at the source code -- Bam! -- the manipulation can take place. Or it could output the blueprint to a really nifty technology, and when we implement it, it has some surreptitious side effect that the A.I. had planned. The point here is that we should not be confident in our ability to keep a superintelligent genie locked up in its bottle forever. Sooner or later, it will out.\n\n\n13:27\nI believe that the answer here is to figure out how to create superintelligent A.I. such that even if -- when -- it escapes, it is still safe because it is fundamentally on our side because it shares our values. I see no way around this difficult problem.\n\n\n13:44\nNow, I'm actually fairly optimistic that this problem can be solved. We wouldn't have to write down a long list of everything we care about, or worse yet, spell it out in some computer language like C++ or Python, that would be a task beyond hopeless. Instead, we would create an A.I. that uses its intelligence to learn what we value, and its motivation system is constructed in such a way that it is motivated to pursue our values or to perform actions that it predicts we would approve of. We would thus leverage its intelligence as much as possible to solve the problem of value-loading.\n\n\n14:24\nThis can happen, and the outcome could be very good for humanity. But it doesn't happen automatically. The initial conditions for the intelligence explosion might need to be set up in just the right way if we are to have a controlled detonation. The values that the A.I. has need to match ours, not just in the familiar context, like where we can easily check how the A.I. behaves, but also in all novel contexts that the A.I. might encounter in the indefinite future.\n\n\n14:54\nAnd there are also some esoteric issues that would need to be solved, sorted out: the exact details of its decision theory, how to deal with logical uncertainty and so forth. So the technical problems that need to be solved to make this work look quite difficult -- not as difficult as making a superintelligent A.I., but fairly difficult. Here is the worry: Making superintelligent A.I. is a really hard challenge. Making superintelligent A.I. that is safe involves some additional challenge on top of that. The risk is that if somebody figures out how to crack the first challenge without also having cracked the additional challenge of ensuring perfect safety.\n\n\n15:37\nSo I think that we should work out a solution to the control problem in advance, so that we have it available by the time it is needed. Now it might be that we cannot solve the entire control problem in advance because maybe some elements can only be put in place once you know the details of the architecture where it will be implemented. But the more of the control problem that we solve in advance, the better the odds that the transition to the machine intelligence era will go well.\n\n\n16:06\nThis to me looks like a thing that is well worth doing and I can imagine that if things turn out okay, that people a million years from now look back at this century and it might well be that they say that the one thing we did that really mattered was to get this thing right.\n\n\n16:24\nThank you.\n\n\n16:26\n(Applause)\n\n\nSteve Jobs at Standford commencement 2015\n\u00b6\n\n\n'You've got to find what you love,' Jobs says\n\u00b6\n\n\nThis is a prepared text of the Commencement address delivered by Steve Jobs, CEO of Apple Computer and of Pixar Animation Studios, on June 12, 2005.\n\u00b6\n\n\nI am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I've ever gotten to a college graduation. Today I want to tell you three stories from my life. That's it. No big deal. Just three stories.\n\n\nThe first story is about connecting the dots.\n\n\nI dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. So why did I drop out?\n\n\nIt started before I was born. My biological mother was a young, unwed college graduate student, and she decided to put me up for adoption. She felt very strongly that I should be adopted by college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife. Except that when I popped out they decided at the last minute that they really wanted a girl. So my parents, who were on a waiting list, got a call in the middle of the night asking: \"We have an unexpected baby boy; do you want him?\" They said: \"Of course.\" My biological mother later found out that my mother had never graduated from college and that my father had never graduated from high school. She refused to sign the final adoption papers. She only relented a few months later when my parents promised that I would someday go to college.\n\n\nAnd 17 years later I did go to college. But I naively chose a college that was almost as expensive as Stanford, and all of my working-class parents' savings were being spent on my college tuition. After six months, I couldn't see the value in it. I had no idea what I wanted to do with my life and no idea how college was going to help me figure it out. And here I was spending all of the money my parents had saved their entire life. So I decided to drop out and trust that it would all work out OK. It was pretty scary at the time, but looking back it was one of the best decisions I ever made. The minute I dropped out I could stop taking the required classes that didn't interest me, and begin dropping in on the ones that looked interesting.\n\n\nIt wasn't all romantic. I didn't have a dorm room, so I slept on the floor in friends' rooms, I returned Coke bottles for the 5\u00a2 deposits to buy food with, and I would walk the 7 miles across town every Sunday night to get one good meal a week at the Hare Krishna temple. I loved it. And much of what I stumbled into by following my curiosity and intuition turned out to be priceless later on. Let me give you one example:\n\n\nReed College at that time offered perhaps the best calligraphy instruction in the country. Throughout the campus every poster, every label on every drawer, was beautifully hand calligraphed. Because I had dropped out and didn't have to take the normal classes, I decided to take a calligraphy class to learn how to do this. I learned about serif and sans serif typefaces, about varying the amount of space between different letter combinations, about what makes great typography great. It was beautiful, historical, artistically subtle in a way that science can't capture, and I found it fascinating.\n\n\nNone of this had even a hope of any practical application in my life. But 10 years later, when we were designing the first Macintosh computer, it all came back to me. And we designed it all into the Mac. It was the first computer with beautiful typography. If I had never dropped in on that single course in college, the Mac would have never had multiple typefaces or proportionally spaced fonts. And since Windows just copied the Mac, it's likely that no personal computer would have them. If I had never dropped out, I would have never dropped in on this calligraphy class, and personal computers might not have the wonderful typography that they do. Of course it was impossible to connect the dots looking forward when I was in college. But it was very, very clear looking backward 10 years later.\n\n\nAgain, you can't connect the dots looking forward; you can only connect them looking backward. So you have to trust that the dots will somehow connect in your future. You have to trust in something \u2014 your gut, destiny, life, karma, whatever. This approach has never let me down, and it has made all the difference in my life.\n\n\nMy second story is about love and loss.\n\n\nI was lucky \u2014 I found what I loved to do early in life. Woz and I started Apple in my parents' garage when I was 20. We worked hard, and in 10 years Apple had grown from just the two of us in a garage into a $2 billion company with over 4,000 employees. We had just released our finest creation \u2014 the Macintosh \u2014 a year earlier, and I had just turned 30. And then I got fired. How can you get fired from a company you started? Well, as Apple grew we hired someone who I thought was very talented to run the company with me, and for the first year or so things went well. But then our visions of the future began to diverge and eventually we had a falling out. When we did, our Board of Directors sided with him. So at 30 I was out. And very publicly out. What had been the focus of my entire adult life was gone, and it was devastating.\n\n\nI really didn't know what to do for a few months. I felt that I had let the previous generation of entrepreneurs down \u2014 that I had dropped the baton as it was being passed to me. I met with David Packard and Bob Noyce and tried to apologize for screwing up so badly. I was a very public failure, and I even thought about running away from the valley. But something slowly began to dawn on me \u2014 I still loved what I did. The turn of events at Apple had not changed that one bit. I had been rejected, but I was still in love. And so I decided to start over.\n\n\nI didn't see it then, but it turned out that getting fired from Apple was the best thing that could have ever happened to me. The heaviness of being successful was replaced by the lightness of being a beginner again, less sure about everything. It freed me to enter one of the most creative periods of my life.\n\n\nDuring the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the world's first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I returned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.\n\n\nI'm pretty sure none of this would have happened if I hadn't been fired from Apple. It was awful tasting medicine, but I guess the patient needed it. Sometimes life hits you in the head with a brick. Don't lose faith. I'm convinced that the only thing that kept me going was that I loved what I did. You've got to find what you love. And that is as true for your work as it is for your lovers. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do. If you haven't found it yet, keep looking. Don't settle. As with all matters of the heart, you'll know when you find it. And, like any great relationship, it just gets better and better as the years roll on. So keep looking until you find it. Don't settle.\n\n\nMy third story is about death.\n\n\nWhen I was 17, I read a quote that went something like: \"If you live each day as if it was your last, someday you'll most certainly be right.\" It made an impression on me, and since then, for the past 33 years, I have looked in the mirror every morning and asked myself: \"If today were the last day of my life, would I want to do what I am about to do today?\" And whenever the answer has been \"No\" for too many days in a row, I know I need to change something.\n\n\nRemembering that I'll be dead soon is the most important tool I've ever encountered to help me make the big choices in life. Because almost everything \u2014 all external expectations, all pride, all fear of embarrassment or failure \u2014 these things just fall away in the face of death, leaving only what is truly important. Remembering that you are going to die is the best way I know to avoid the trap of thinking you have something to lose. You are already naked. There is no reason not to follow your heart.\n\n\nAbout a year ago I was diagnosed with cancer. I had a scan at 7:30 in the morning, and it clearly showed a tumor on my pancreas. I didn't even know what a pancreas was. The doctors told me this was almost certainly a type of cancer that is incurable, and that I should expect to live no longer than three to six months. My doctor advised me to go home and get my affairs in order, which is doctor's code for prepare to die. It means to try to tell your kids everything you thought you'd have the next 10 years to tell them in just a few months. It means to make sure everything is buttoned up so that it will be as easy as possible for your family. It means to say your goodbyes.\n\n\nI lived with that diagnosis all day. Later that evening I had a biopsy, where they stuck an endoscope down my throat, through my stomach and into my intestines, put a needle into my pancreas and got a few cells from the tumor. I was sedated, but my wife, who was there, told me that when they viewed the cells under a microscope the doctors started crying because it turned out to be a very rare form of pancreatic cancer that is curable with surgery. I had the surgery and I'm fine now.\n\n\nThis was the closest I've been to facing death, and I hope it's the closest I get for a few more decades. Having lived through it, I can now say this to you with a bit more certainty than when death was a useful but purely intellectual concept:\n\n\nNo one wants to die. Even people who want to go to heaven don't want to die to get there. And yet death is the destination we all share. No one has ever escaped it. And that is as it should be, because Death is very likely the single best invention of Life. It is Life's change agent. It clears out the old to make way for the new. Right now the new is you, but someday not too long from now, you will gradually become the old and be cleared away. Sorry to be so dramatic, but it is quite true.\n\n\nYour time is limited, so don't waste it living someone else's life. Don't be trapped by dogma \u2014 which is living with the results of other people's thinking. Don't let the noise of others' opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary.\n\n\nWhen I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation. It was created by a fellow named Stewart Brand not far from here in Menlo Park, and he brought it to life with his poetic touch. This was in the late 1960s, before personal computers and desktop publishing, so it was all made with typewriters, scissors and Polaroid cameras. It was sort of like Google in paperback form, 35 years before Google came along: It was idealistic, and overflowing with neat tools and great notions.\n\n\nStewart and his team put out several issues of The Whole Earth Catalog, and then when it had run its course, they put out a final issue. It was the mid-1970s, and I was your age. On the back cover of their final issue was a photograph of an early morning country road, the kind you might find yourself hitchhiking on if you were so adventurous. Beneath it were the words: \"Stay Hungry. Stay Foolish.\" It was their farewell message as they signed off. Stay Hungry. Stay Foolish. And I have always wished that for myself. And now, as you graduate to begin anew, I wish that for you.\n\n\nStay Hungry. Stay Foolish.\n\n\nThank you all very much.\n\n\nMeaning of Stay Hungry, Stay Foolish\n\u00b6\n\n\nStay hungry: never be satisfied, and always push yourself.\n\n\nStay foolish: do (or be willing to keep trying) the things people say cannot be done.",
            "title": "May"
        },
        {
            "location": "/2018/05/#may-4-2018",
            "text": "",
            "title": "May 4, 2018"
        },
        {
            "location": "/2018/05/#quote-of-the-day",
            "text": "The next frontiers of scientific discovery will be pioneered by those who can transcend the traditional boundaries of science. -- Eric Schmidt, Former CEO of Google",
            "title": "Quote of the Day"
        },
        {
            "location": "/2018/05/#ted-talk-nick-bostrom-ted-2015-what-happens-when-our-computers-get-smarter-than-we-are",
            "text": "",
            "title": "TED Talk - Nick Bostrom (TED 2015): What happens when our computers get smarter than we are?"
        },
        {
            "location": "/2018/05/#video",
            "text": "Nick Bostrom (TED 2015): What happens when our computers get smarter than we are?",
            "title": "Video"
        },
        {
            "location": "/2018/05/#notes",
            "text": "It's a curious shape for a normal condition:  curious  here means  strange and unusual .   It was curious that she didn't tell anyone.\nThere was a curious mixture of people in the audience.\nIt was a curious feeling, as though we were floating on the air.   as thought: same as  as if , used to describe how a situation seems to be.   They stared at me as though I was crazy.\nShe looked as though she'd had some bad news.\nShe behaved as though he wasn't there.\nI felt as though I'd been lying in the sun for hours.",
            "title": "Notes"
        },
        {
            "location": "/2018/05/#sentences",
            "text": "So a bunch of relatively minor changes take us from Kanzi to Witten, from broken-off tree branches to intercontinental ballistic missiles:   break off: if part of something breaks off or if you break it off, it comes off or is removed by force.  broken-off tree branches  means those tree branches that has been removed by force.  intercontinental ballistic missiles(ICBM): \u6d32\u9645\u5f39\u9053\u5bfc\u5f39. In this sentence, that means, we human species have evolved a lot due to a bunch of relatively minor changes which has made us more intelligent, and      the more intelligent we  have created intercontinental ballistic missiles, we no longer use broken-off tree branches like ancient ancestors.",
            "title": "Sentences"
        },
        {
            "location": "/2018/05/#transcripts",
            "text": "00:12\nI work with a bunch of mathematicians, philosophers and computer scientists, and we sit around and think about the future of machine intelligence, among other things. Some people think that some of these things are sort of science fiction-y, far out there, crazy. But I like to say, okay, let's look at the modern human condition. (Laughter) This is the normal way for things to be.  00:41\nBut if we think about it, we are actually recently arrived guests on this planet, the human species. Think about if Earth was created one year ago, the human species, then, would be 10 minutes old. The industrial era started two seconds ago. Another way to look at this is to think of world GDP over the last 10,000 years, I've actually taken the trouble to plot this for you in a graph. It looks like this. (Laughter) It's a curious shape for a normal condition. I sure wouldn't want to sit on it. (Laughter)  01:19\nLet's ask ourselves, what is the cause of this current anomaly? Some people would say it's technology. Now it's true, technology has accumulated through human history, and right now, technology advances extremely rapidly -- that is the proximate cause, that's why we are currently so very productive. But I like to think back further to the ultimate cause.  01:45\nLook at these two highly distinguished gentlemen: We have Kanzi -- he's mastered 200 lexical tokens, an incredible feat. And Ed Witten unleashed the second superstring revolution. If we look under the hood, this is what we find: basically the same thing. One is a little larger, it maybe also has a few tricks in the exact way it's wired. These invisible differences cannot be too complicated, however, because there have only been 250,000 generations since our last common ancestor. We know that complicated mechanisms take a long time to evolve. So a bunch of relatively minor changes take us from Kanzi to Witten, from broken-off tree branches to intercontinental ballistic missiles.  02:32\nSo this then seems pretty obvious that everything we've achieved, and everything we care about, depends crucially on some relatively minor changes that made the human mind. And the corollary, of course, is that any further changes that could significantly change the substrate of thinking could have potentially enormous consequences.  02:56\nSome of my colleagues think we're on the verge of something that could cause a profound change in that substrate, and that is machine superintelligence. Artificial intelligence used to be about putting commands in a box. You would have human programmers that would painstakingly handcraft knowledge items. You build up these expert systems, and they were kind of useful for some purposes, but they were very brittle, you couldn't scale them. Basically, you got out only what you put in. But since then, a paradigm shift has taken place in the field of artificial intelligence.  03:30\nToday, the action is really around machine learning. So rather than handcrafting knowledge representations and features, we create algorithms that learn, often from raw perceptual data. Basically the same thing that the human infant does. The result is A.I. that is not limited to one domain -- the same system can learn to translate between any pairs of languages, or learn to play any computer game on the Atari console. Now of course, A.I. is still nowhere near having the same powerful, cross-domain ability to learn and plan as a human being has. The cortex still has some algorithmic tricks that we don't yet know how to match in machines.  04:19\nSo the question is, how far are we from being able to match those tricks? A couple of years ago, we did a survey of some of the world's leading A.I. experts, to see what they think, and one of the questions we asked was, \"By which year do you think there is a 50 percent probability that we will have achieved human-level machine intelligence?\" We defined human-level here as the ability to perform almost any job at least as well as an adult human, so real human-level, not just within some limited domain. And the median answer was 2040 or 2050, depending on precisely which group of experts we asked. Now, it could happen much, much later, or sooner, the truth is nobody really knows.  05:05\nWhat we do know is that the ultimate limit to information processing in a machine substrate lies far outside the limits in biological tissue. This comes down to physics. A biological neuron fires, maybe, at 200 hertz, 200 times a second. But even a present-day transistor operates at the Gigahertz. Neurons propagate slowly in axons, 100 meters per second, tops. But in computers, signals can travel at the speed of light. There are also size limitations, like a human brain has to fit inside a cranium, but a computer can be the size of a warehouse or larger. So the potential for superintelligence lies dormant in matter, much like the power of the atom lay dormant throughout human history, patiently waiting there until 1945. In this century, scientists may learn to awaken the power of artificial intelligence. And I think we might then see an intelligence explosion.  06:10\nNow most people, when they think about what is smart and what is dumb, I think have in mind a picture roughly like this. So at one end we have the village idiot, and then far over at the other side we have Ed Witten, or Albert Einstein, or whoever your favorite guru is. But I think that from the point of view of artificial intelligence, the true picture is actually probably more like this: AI starts out at this point here, at zero intelligence, and then, after many, many years of really hard work, maybe eventually we get to mouse-level artificial intelligence, something that can navigate cluttered environments as well as a mouse can. And then, after many, many more years of really hard work, lots of investment, maybe eventually we get to chimpanzee-level artificial intelligence. And then, after even more years of really, really hard work, we get to village idiot artificial intelligence. And a few moments later, we are beyond Ed Witten. The train doesn't stop at Humanville Station. It's likely, rather, to swoosh right by.  07:14\nNow this has profound implications, particularly when it comes to questions of power. For example, chimpanzees are strong -- pound for pound, a chimpanzee is about twice as strong as a fit human male. And yet, the fate of Kanzi and his pals depends a lot more on what we humans do than on what the chimpanzees do themselves. Once there is superintelligence, the fate of humanity may depend on what the superintelligence does. Think about it: Machine intelligence is the last invention that humanity will ever need to make. Machines will then be better at inventing than we are, and they'll be doing so on digital timescales. What this means is basically a telescoping of the future. Think of all the crazy technologies that you could have imagined maybe humans could have developed in the fullness of time: cures for aging, space colonization, self-replicating nanobots or uploading of minds into computers, all kinds of science fiction-y stuff that's nevertheless consistent with the laws of physics. All of this superintelligence could develop, and possibly quite rapidly.  08:24\nNow, a superintelligence with such technological maturity would be extremely powerful, and at least in some scenarios, it would be able to get what it wants. We would then have a future that would be shaped by the preferences of this A.I. Now a good question is, what are those preferences? Here it gets trickier. To make any headway with this, we must first of all avoid anthropomorphizing. And this is ironic because every newspaper article about the future of A.I. has a picture of this: So I think what we need to do is to conceive of the issue more abstractly, not in terms of vivid Hollywood scenarios.  09:09\nWe need to think of intelligence as an optimization process, a process that steers the future into a particular set of configurations. A superintelligence is a really strong optimization process. It's extremely good at using available means to achieve a state in which its goal is realized. This means that there is no necessary connection between being highly intelligent in this sense, and having an objective that we humans would find worthwhile or meaningful.  09:39\nSuppose we give an A.I. the goal to make humans smile. When the A.I. is weak, it performs useful or amusing actions that cause its user to smile. When the A.I. becomes superintelligent, it realizes that there is a more effective way to achieve this goal: take control of the world and stick electrodes into the facial muscles of humans to cause constant, beaming grins. Another example, suppose we give A.I. the goal to solve a difficult mathematical problem. When the A.I. becomes superintelligent, it realizes that the most effective way to get the solution to this problem is by transforming the planet into a giant computer, so as to increase its thinking capacity. And notice that this gives the A.I.s an instrumental reason to do things to us that we might not approve of. Human beings in this model are threats, we could prevent the mathematical problem from being solved.  10:29\nOf course, perceivably things won't go wrong in these particular ways; these are cartoon examples. But the general point here is important: if you create a really powerful optimization process to maximize for objective x, you better make sure that your definition of x incorporates everything you care about. This is a lesson that's also taught in many a myth. King Midas wishes that everything he touches be turned into gold. He touches his daughter, she turns into gold. He touches his food, it turns into gold. This could become practically relevant, not just as a metaphor for greed, but as an illustration of what happens if you create a powerful optimization process and give it misconceived or poorly specified goals.  11:16\nNow you might say, if a computer starts sticking electrodes into people's faces, we'd just shut it off. A, this is not necessarily so easy to do if we've grown dependent on the system -- like, where is the off switch to the Internet? B, why haven't the chimpanzees flicked the off switch to humanity, or the Neanderthals? They certainly had reasons. We have an off switch, for example, right here. (Choking) The reason is that we are an intelligent adversary; we can anticipate threats and plan around them. But so could a superintelligent agent, and it would be much better at that than we are. The point is, we should not be confident that we have this under control here.  12:04\nAnd we could try to make our job a little bit easier by, say, putting the A.I. in a box, like a secure software environment, a virtual reality simulation from which it cannot escape. But how confident can we be that the A.I. couldn't find a bug. Given that merely human hackers find bugs all the time, I'd say, probably not very confident. So we disconnect the ethernet cable to create an air gap, but again, like merely human hackers routinely transgress air gaps using social engineering. Right now, as I speak, I'm sure there is some employee out there somewhere who has been talked into handing out her account details by somebody claiming to be from the I.T. department.  12:46\nMore creative scenarios are also possible, like if you're the A.I., you can imagine wiggling electrodes around in your internal circuitry to create radio waves that you can use to communicate. Or maybe you could pretend to malfunction, and then when the programmers open you up to see what went wrong with you, they look at the source code -- Bam! -- the manipulation can take place. Or it could output the blueprint to a really nifty technology, and when we implement it, it has some surreptitious side effect that the A.I. had planned. The point here is that we should not be confident in our ability to keep a superintelligent genie locked up in its bottle forever. Sooner or later, it will out.  13:27\nI believe that the answer here is to figure out how to create superintelligent A.I. such that even if -- when -- it escapes, it is still safe because it is fundamentally on our side because it shares our values. I see no way around this difficult problem.  13:44\nNow, I'm actually fairly optimistic that this problem can be solved. We wouldn't have to write down a long list of everything we care about, or worse yet, spell it out in some computer language like C++ or Python, that would be a task beyond hopeless. Instead, we would create an A.I. that uses its intelligence to learn what we value, and its motivation system is constructed in such a way that it is motivated to pursue our values or to perform actions that it predicts we would approve of. We would thus leverage its intelligence as much as possible to solve the problem of value-loading.  14:24\nThis can happen, and the outcome could be very good for humanity. But it doesn't happen automatically. The initial conditions for the intelligence explosion might need to be set up in just the right way if we are to have a controlled detonation. The values that the A.I. has need to match ours, not just in the familiar context, like where we can easily check how the A.I. behaves, but also in all novel contexts that the A.I. might encounter in the indefinite future.  14:54\nAnd there are also some esoteric issues that would need to be solved, sorted out: the exact details of its decision theory, how to deal with logical uncertainty and so forth. So the technical problems that need to be solved to make this work look quite difficult -- not as difficult as making a superintelligent A.I., but fairly difficult. Here is the worry: Making superintelligent A.I. is a really hard challenge. Making superintelligent A.I. that is safe involves some additional challenge on top of that. The risk is that if somebody figures out how to crack the first challenge without also having cracked the additional challenge of ensuring perfect safety.  15:37\nSo I think that we should work out a solution to the control problem in advance, so that we have it available by the time it is needed. Now it might be that we cannot solve the entire control problem in advance because maybe some elements can only be put in place once you know the details of the architecture where it will be implemented. But the more of the control problem that we solve in advance, the better the odds that the transition to the machine intelligence era will go well.  16:06\nThis to me looks like a thing that is well worth doing and I can imagine that if things turn out okay, that people a million years from now look back at this century and it might well be that they say that the one thing we did that really mattered was to get this thing right.  16:24\nThank you.  16:26\n(Applause)",
            "title": "Transcripts"
        },
        {
            "location": "/2018/05/#steve-jobs-at-standford-commencement-2015",
            "text": "",
            "title": "Steve Jobs at Standford commencement 2015"
        },
        {
            "location": "/2018/05/#youve-got-to-find-what-you-love-jobs-says",
            "text": "",
            "title": "'You've got to find what you love,' Jobs says"
        },
        {
            "location": "/2018/05/#this-is-a-prepared-text-of-the-commencement-address-delivered-by-steve-jobs-ceo-of-apple-computer-and-of-pixar-animation-studios-on-june-12-2005",
            "text": "I am honored to be with you today at your commencement from one of the finest universities in the world. I never graduated from college. Truth be told, this is the closest I've ever gotten to a college graduation. Today I want to tell you three stories from my life. That's it. No big deal. Just three stories.  The first story is about connecting the dots.  I dropped out of Reed College after the first 6 months, but then stayed around as a drop-in for another 18 months or so before I really quit. So why did I drop out?  It started before I was born. My biological mother was a young, unwed college graduate student, and she decided to put me up for adoption. She felt very strongly that I should be adopted by college graduates, so everything was all set for me to be adopted at birth by a lawyer and his wife. Except that when I popped out they decided at the last minute that they really wanted a girl. So my parents, who were on a waiting list, got a call in the middle of the night asking: \"We have an unexpected baby boy; do you want him?\" They said: \"Of course.\" My biological mother later found out that my mother had never graduated from college and that my father had never graduated from high school. She refused to sign the final adoption papers. She only relented a few months later when my parents promised that I would someday go to college.  And 17 years later I did go to college. But I naively chose a college that was almost as expensive as Stanford, and all of my working-class parents' savings were being spent on my college tuition. After six months, I couldn't see the value in it. I had no idea what I wanted to do with my life and no idea how college was going to help me figure it out. And here I was spending all of the money my parents had saved their entire life. So I decided to drop out and trust that it would all work out OK. It was pretty scary at the time, but looking back it was one of the best decisions I ever made. The minute I dropped out I could stop taking the required classes that didn't interest me, and begin dropping in on the ones that looked interesting.  It wasn't all romantic. I didn't have a dorm room, so I slept on the floor in friends' rooms, I returned Coke bottles for the 5\u00a2 deposits to buy food with, and I would walk the 7 miles across town every Sunday night to get one good meal a week at the Hare Krishna temple. I loved it. And much of what I stumbled into by following my curiosity and intuition turned out to be priceless later on. Let me give you one example:  Reed College at that time offered perhaps the best calligraphy instruction in the country. Throughout the campus every poster, every label on every drawer, was beautifully hand calligraphed. Because I had dropped out and didn't have to take the normal classes, I decided to take a calligraphy class to learn how to do this. I learned about serif and sans serif typefaces, about varying the amount of space between different letter combinations, about what makes great typography great. It was beautiful, historical, artistically subtle in a way that science can't capture, and I found it fascinating.  None of this had even a hope of any practical application in my life. But 10 years later, when we were designing the first Macintosh computer, it all came back to me. And we designed it all into the Mac. It was the first computer with beautiful typography. If I had never dropped in on that single course in college, the Mac would have never had multiple typefaces or proportionally spaced fonts. And since Windows just copied the Mac, it's likely that no personal computer would have them. If I had never dropped out, I would have never dropped in on this calligraphy class, and personal computers might not have the wonderful typography that they do. Of course it was impossible to connect the dots looking forward when I was in college. But it was very, very clear looking backward 10 years later.  Again, you can't connect the dots looking forward; you can only connect them looking backward. So you have to trust that the dots will somehow connect in your future. You have to trust in something \u2014 your gut, destiny, life, karma, whatever. This approach has never let me down, and it has made all the difference in my life.  My second story is about love and loss.  I was lucky \u2014 I found what I loved to do early in life. Woz and I started Apple in my parents' garage when I was 20. We worked hard, and in 10 years Apple had grown from just the two of us in a garage into a $2 billion company with over 4,000 employees. We had just released our finest creation \u2014 the Macintosh \u2014 a year earlier, and I had just turned 30. And then I got fired. How can you get fired from a company you started? Well, as Apple grew we hired someone who I thought was very talented to run the company with me, and for the first year or so things went well. But then our visions of the future began to diverge and eventually we had a falling out. When we did, our Board of Directors sided with him. So at 30 I was out. And very publicly out. What had been the focus of my entire adult life was gone, and it was devastating.  I really didn't know what to do for a few months. I felt that I had let the previous generation of entrepreneurs down \u2014 that I had dropped the baton as it was being passed to me. I met with David Packard and Bob Noyce and tried to apologize for screwing up so badly. I was a very public failure, and I even thought about running away from the valley. But something slowly began to dawn on me \u2014 I still loved what I did. The turn of events at Apple had not changed that one bit. I had been rejected, but I was still in love. And so I decided to start over.  I didn't see it then, but it turned out that getting fired from Apple was the best thing that could have ever happened to me. The heaviness of being successful was replaced by the lightness of being a beginner again, less sure about everything. It freed me to enter one of the most creative periods of my life.  During the next five years, I started a company named NeXT, another company named Pixar, and fell in love with an amazing woman who would become my wife. Pixar went on to create the world's first computer animated feature film, Toy Story, and is now the most successful animation studio in the world. In a remarkable turn of events, Apple bought NeXT, I returned to Apple, and the technology we developed at NeXT is at the heart of Apple's current renaissance. And Laurene and I have a wonderful family together.  I'm pretty sure none of this would have happened if I hadn't been fired from Apple. It was awful tasting medicine, but I guess the patient needed it. Sometimes life hits you in the head with a brick. Don't lose faith. I'm convinced that the only thing that kept me going was that I loved what I did. You've got to find what you love. And that is as true for your work as it is for your lovers. Your work is going to fill a large part of your life, and the only way to be truly satisfied is to do what you believe is great work. And the only way to do great work is to love what you do. If you haven't found it yet, keep looking. Don't settle. As with all matters of the heart, you'll know when you find it. And, like any great relationship, it just gets better and better as the years roll on. So keep looking until you find it. Don't settle.  My third story is about death.  When I was 17, I read a quote that went something like: \"If you live each day as if it was your last, someday you'll most certainly be right.\" It made an impression on me, and since then, for the past 33 years, I have looked in the mirror every morning and asked myself: \"If today were the last day of my life, would I want to do what I am about to do today?\" And whenever the answer has been \"No\" for too many days in a row, I know I need to change something.  Remembering that I'll be dead soon is the most important tool I've ever encountered to help me make the big choices in life. Because almost everything \u2014 all external expectations, all pride, all fear of embarrassment or failure \u2014 these things just fall away in the face of death, leaving only what is truly important. Remembering that you are going to die is the best way I know to avoid the trap of thinking you have something to lose. You are already naked. There is no reason not to follow your heart.  About a year ago I was diagnosed with cancer. I had a scan at 7:30 in the morning, and it clearly showed a tumor on my pancreas. I didn't even know what a pancreas was. The doctors told me this was almost certainly a type of cancer that is incurable, and that I should expect to live no longer than three to six months. My doctor advised me to go home and get my affairs in order, which is doctor's code for prepare to die. It means to try to tell your kids everything you thought you'd have the next 10 years to tell them in just a few months. It means to make sure everything is buttoned up so that it will be as easy as possible for your family. It means to say your goodbyes.  I lived with that diagnosis all day. Later that evening I had a biopsy, where they stuck an endoscope down my throat, through my stomach and into my intestines, put a needle into my pancreas and got a few cells from the tumor. I was sedated, but my wife, who was there, told me that when they viewed the cells under a microscope the doctors started crying because it turned out to be a very rare form of pancreatic cancer that is curable with surgery. I had the surgery and I'm fine now.  This was the closest I've been to facing death, and I hope it's the closest I get for a few more decades. Having lived through it, I can now say this to you with a bit more certainty than when death was a useful but purely intellectual concept:  No one wants to die. Even people who want to go to heaven don't want to die to get there. And yet death is the destination we all share. No one has ever escaped it. And that is as it should be, because Death is very likely the single best invention of Life. It is Life's change agent. It clears out the old to make way for the new. Right now the new is you, but someday not too long from now, you will gradually become the old and be cleared away. Sorry to be so dramatic, but it is quite true.  Your time is limited, so don't waste it living someone else's life. Don't be trapped by dogma \u2014 which is living with the results of other people's thinking. Don't let the noise of others' opinions drown out your own inner voice. And most important, have the courage to follow your heart and intuition. They somehow already know what you truly want to become. Everything else is secondary.  When I was young, there was an amazing publication called The Whole Earth Catalog, which was one of the bibles of my generation. It was created by a fellow named Stewart Brand not far from here in Menlo Park, and he brought it to life with his poetic touch. This was in the late 1960s, before personal computers and desktop publishing, so it was all made with typewriters, scissors and Polaroid cameras. It was sort of like Google in paperback form, 35 years before Google came along: It was idealistic, and overflowing with neat tools and great notions.  Stewart and his team put out several issues of The Whole Earth Catalog, and then when it had run its course, they put out a final issue. It was the mid-1970s, and I was your age. On the back cover of their final issue was a photograph of an early morning country road, the kind you might find yourself hitchhiking on if you were so adventurous. Beneath it were the words: \"Stay Hungry. Stay Foolish.\" It was their farewell message as they signed off. Stay Hungry. Stay Foolish. And I have always wished that for myself. And now, as you graduate to begin anew, I wish that for you.  Stay Hungry. Stay Foolish.  Thank you all very much.",
            "title": "This is a prepared text of the Commencement address delivered by Steve Jobs, CEO of Apple Computer and of Pixar Animation Studios, on June 12, 2005."
        },
        {
            "location": "/2018/05/#meaning-of-stay-hungry-stay-foolish",
            "text": "Stay hungry: never be satisfied, and always push yourself.  Stay foolish: do (or be willing to keep trying) the things people say cannot be done.",
            "title": "Meaning of Stay Hungry, Stay Foolish"
        },
        {
            "location": "/2018/06/",
            "text": "June 4, 2018\n\u00b6\n\n\nQuote of the Day\n\u00b6\n\n\n\n\nTeach self-denial and make its practice pleasure, and you can create for the world a destiny more sublime that ever issued from the brain of the wildest dreamer. -- Sir Walter Scott\n\n\n\n\nMeaning: This quote seems overstated and exaggerated, although it has some truth to it. \"Self-denial \" is \nharsh-sounding\n but means self-restraint or holding back on one's selfish desires in favor of caring about others. Sometimes you to have to deny yourself some selfish satisfaction in order to see to the welfare of other people. The writer of the quote believes that if people were taught to put others before themselves and, \nmoreover\n, to enjoy \nthe virtue of altruism\n, the world would be a wonderful place, in a way we can hardly imagine. It is no doubt true that giving up self-interest in favor of altruism would make a better world. But the way this idea is stated with \nsuch an excessive tone\n to me makes it a little weird. It could have been stated more clearly and more effectively by a better writer. \nSource\n\n\n\n\nPeople often overestimate what will happen in the next two years and underestimate what will happen in ten. -- Bill Gates\n\n\n\n\nPhrase\n\u00b6\n\n\nsee eye to eye\n: be in full agreement. \n\n\nEg: The boss and I do not always see eye to eye.\n\n\nTED - How to turn a group of strangers into a team\n\u00b6\n\n\nAmy Edmondson\n\n\nRecommended: \nClick Here for the Video on TED Official Website\n\n\n\n\n\nTranscript\n\u00b6\n\n\n00:12\nIt's August 5, 2010. A massive collapse at the San Jos\u00e9 Copper Mine in Northern Chile has left 33 men trapped half a mile -- that's two Empire State Buildings -- below some of the hardest rock in the world. They will find their way to a small refuge designed for this purpose, where they will find intense heat, filth and about enough food for two men for 10 days. Aboveground, it doesn't take long for the experts to figure out that there is no solution. No drilling technology in the industry is capable of getting through rock that hard and that deep fast enough to save their lives. It's not exactly clear where the refuge is. It's not even clear if the miners are alive. And it's not even clear who's in charge. Yet, within 70 days, all 33 of these men will be brought to the surface alive. This remarkable story is a case study in the power of teaming.\n\n\n01:24\nSo what's \"teaming\"? Teaming is teamwork on the fly. It's coordinating and collaborating with people across boundaries of all kinds -- expertise, distance, time zone, you name it -- to get work done.\n\n\n01:39\nThink of your favorite sports team, because this is different. Sports teams work together: that magic, those game-saving plays. Now, sports teams win because they practice. But you can only practice if you have the same members over time. And so you can think of teaming ... Sports teams embody the definition of a team, the formal definition. It's a stable, bounded, reasonably small group of people who are interdependent in achieving a shared outcome. You can think of teaming as a kind of pickup game in the park, in contrast to the formal, well-practiced team. Now, which one is going to win in a playoff? The answer is obvious. So why do I study teaming? It's because it's the way more and more of us have to work today. With 24/7 global fast-paced operations, crazy shifting schedules and ever-narrower expertise, more and more of us have to work with different people all the time to get our work done. We don't have the luxury of stable teams. Now, when you can have that luxury, by all means do it. But increasingly for a lot of the work we do today, we don't have that option. One place where this is true is hospitals. This is where I've done a lot of my research over the years. So it turns out hospitals have to be open 24/7. And patients -- well, they're all different. They're all different in complicated and unique ways. The average hospitalized patient is seen by 60 or so different caregivers throughout his stay. They come from different shifts, different specialties, different areas of expertise, and they may not even know each other's name. But they have to coordinate in order for the patient to get great care. And when they don't, the results can be tragic.\n\n\n03:36\nOf course, in teaming, the stakes aren't always life and death. Consider what it takes to create an animated film, an award-winning animated film. I had the good fortune to go to Disney Animation and study over 900 scientists, artists, storytellers, computer scientists as they teamed up in constantly changing configurations to create amazing outcomes like \"Frozen.\" They just work together, and never the same group twice, not knowing what's going to happen next. Now, taking care of patients in the emergency room and designing an animated film are obviously very different work. Yet underneath the differences, they have a lot in common. You have to get different expertise at different times, you don't have fixed roles, you don't have fixed deliverables, you're going to be doing a lot of things that have never been done before, and you can't do it in a stable team.\n\n\n04:36\nNow, this way of working isn't easy, but as I said, it's more and more the way many of us have to work, so we have to understand it. And I would argue that it's especially needed for work that's complex and unpredictable and for solving big problems. Paul Polman, the Unilever CEO, put this really well when he said, \"The issues we face today are so big and so challenging, it becomes quite clear we can't do it alone, and so there is a certain humility in knowing you have to invite people in.\" Issues like food or water scarcity cannot be done by individuals, even by single companies, even by single sectors. So we're reaching out to team across big teaming, grand-scale teaming.\n\n\n05:24\nTake the quest for smart cities. Maybe you've seen some of the rhetoric: mixed-use designs, zero net energy buildings, smart mobility, green, livable, wonderful cities. We have the vocabulary, we have the visions, not to mention the need. We have the technology. Two megatrends -- urbanization, we're fast becoming a more urban planet, and climate change -- have been increasingly pointing to cities as a crucial target for innovation. And now around the world in various locations, people have been teaming up to design and try to create green, livable, smart cities. It's a massive innovation challenge.\n\n\n06:09\nTo understand it better, I studied a start-up -- a smart-city software start-up -- as it teamed up with a real estate developer, some civil engineers, a mayor, an architect, some builders, some tech companies. Their goal was to build a demo smart city from scratch. OK. Five years into the project, not a whole lot had happened. Six years, still no ground broken. It seemed that teaming across industry boundaries was really, really hard. OK, so ... We had inadvertently discovered what I call \"professional culture clash\" with this project. You know, software engineers and real estate developers think differently -- really differently: different values, different time frames -- time frames is a big one -- and different jargon, different language. And so they don't always see eye to eye. I think this is a bigger problem than most of us realize. In fact, I think professional culture clash is a major barrier to building the future that we aspire to build. And so it becomes a problem that we have to understand, a problem that we have to figure out how to crack. So how do you make sure teaming goes well, especially big teaming? This is the question I've been trying to solve for a number of years in many different workplaces with my research.\n\n\n07:46\nNow, to begin to get just a glimpse of the answer to this question, let's go back to Chile. In Chile, we witnessed 10 weeks of teaming by hundreds of individuals from different professions, different companies, different sectors, even different nations. And as this process unfolded, they had lots of ideas, they tried many things, they experimented, they failed, they experienced devastating daily failure, but they picked up, persevered, and went on forward. And really, what we witnessed there was they were able to be humble in the face of the very real challenge ahead, curious -- all of these diverse individuals, diverse expertise especially, nationality as well, were quite curious about what each other brings. And they were willing to take risks to learn fast what might work. And ultimately, 17 days into this remarkable story, ideas came from everywhere. They came from Andr\u00e9 Sougarret, who is a brilliant mining engineer who was appointed by the government to lead the rescue. They came from NASA. They came from Chilean Special Forces. They came from volunteers around the world. And while many of us, including myself, watched from afar, these folks made slow, painful progress through the rock.\n\n\n09:14\nOn the 17\nth\n day, they broke through to the refuge. It's just a remarkable moment. And with just a very small incision, they were able to find it through a bunch of experimental techniques. And then for the next 53 days, that narrow lifeline would be the path where food and medicine and communication would travel, while aboveground, for 53 more days, they continued the teaming to find a way to create a much larger hole and also to design a capsule. This is the capsule. And then on the 69\nth\n day, over 22 painstaking hours, they managed to pull the miners out one by one.\n\n\n09:59\nSo how did they overcome professional culture clash? I would say in a word, it's leadership, but let me be more specific. When teaming works, you can be sure that some leaders, leaders at all levels, have been crystal clear that they don't have the answers. Let's call this \"situational humility.\" It's appropriate humility. We don't know how to do it. You can be sure, as I said before, people were very curious, and this situational humility combined with curiosity creates a sense of psychological safety that allows you take risks with strangers, because let's face it: it's hard to speak up, right? It's hard to ask for help. It's hard to offer an idea that might be a stupid idea if you don't know people very well. You need psychological safety to do that. They overcame what I like to call the basic human challenge: it's hard to learn if you already know. And unfortunately, we're hardwired to think we know. And so we've got to remind ourselves -- and we can do it -- to be curious; to be curious about what others bring. And that curiosity can also spawn a kind of generosity of interpretation.\n\n\n11:11\nBut there's another barrier, and you all know it. You wouldn't be in this room if you didn't know it. And to explain it, I'm going to quote from the movie \"The Paper Chase.\" This, by the way, is what Hollywood thinks a Harvard professor is supposed to look like. You be the judge. The professor in this famous scene, he's welcoming the new 1L class, and he says, \"Look to your left. Look to your right. one of you won't be here next year.\" What message did they hear? \"It's me or you.\" For me to succeed, you must fail. Now, I don't think too many organizations welcome newcomers that way anymore, but still, many times people arrive with that message of scarcity anyway. It's me or you. It's awfully hard to team if you inadvertently see others as competitors.\n\n\n11:57\nSo we have to overcome that one as well, and when we do, the results can be awesome. Abraham Lincoln said once, \"I don't like that man very much. I must get to know him better.\" Think about that -- I don't like him, that means I don't know him well enough. It's extraordinary. This is the mindset, I have to say, this is the mindset you need for effective teaming. In our silos, we can get things done. But when we step back and reach out and reach across, miracles can happen. Miners can be rescued, patients can be saved, beautiful films can be created.\n\n\n12:36\nTo get there, I think there's no better advice than this: look to your left, look to your right. How quickly can you find the unique talents, skills and hopes of your neighbor, and how quickly, in turn, can you convey what you bring? Because for us to team up to build the future we know we can create that none of us can do alone, that's the mindset we need.\n\n\n12:59\nThank you.\n\n\n13:01\n(Applause)\n\n\nExcerpt\n\u00b6\n\n\n\n\na massive collapse: \u91cd\u5927\u574d\u584c\n\n\nleft 33 men trapped half a mile below \nsome of the hardest rock\n in the world\n\n\nfind a small \nrefuge\n designed for this purpose: refuge is a shelter or protection from danger, trouble, etc.\n\n\nfilth\n: any very dirty and unpleasant substance -- \ne.g. The floor was covered in \ngrease\n and filth. -- \ngrease: any thick oil substance, especially one that is used to make machines run smoothly.\n\n\nAboveground, it doesn't take long for the experts to figures out that there is no solution.\n\n\nIt's not exactly clear where the refuge is. \nIt's not even clear if the miners are alive. \nAnd it's not even clear who's in charge.\n\n\nTeaming is \nteamwork on the fly\n: \non the fly\n means quickly and informally, without thought or preparation. Actually this idiom has so many meanings, here the meaning should be \nif you do something on the fly, you do it quickly, without thinking about it  or planning it in advance.\n. E.g. make decisions on the fly.\n\n\nyou name it\n: whatever you can think of (used to express the extent or variety of something) -- It's coordinating and collaborating with people \nacross boundaries of all kinds\n -- expertise, distance, time zone, \nyou name it\n -- to get work done.\n\n\nNow, sports teams win because they practice. But you can only practice if you have the same members \nover time\n.\n\n\nembody: 1. to express or represent an idea or a quality: embody something, e.g. a politician who embodies the hopes of black youth. -- 2. embody something (formal): to include or contain something: e.g. this model embodies many new features.\n\n\npickup: adj, to be used only before noun, (of a sports team) often not planned in advance and that anyone who wants to can join in.\n\n\n\n\n\n\nJune 6, 2018\n\u00b6\n\n\nTED - Don't fear superintelligent AI\n\u00b6\n\n\nGrady Booch\n\n\nRecommended: \nClick Here for the Video on TED Official Website\n\n\n\n\n\n00:12\nWhen I was a kid, I was the quintessential nerd. I think some of you were, too.\n\n\n00:19\n(Laughter)\n\n\n00:20\nAnd you, sir, who laughed the loudest, you probably still are.\n\n\n00:24\n(Laughter)\n\n\n00:26\nI grew up in a small town in the dusty plains of north Texas, the son of a sheriff who was the son of a pastor. Getting into trouble was not an option. And so I started reading calculus books for fun.\n\n\n00:39\n(Laughter)\n\n\n00:40\nYou did, too. That led me to building a laser and a computer and model rockets, and that led me to making rocket fuel in my bedroom. Now, in scientific terms, we call this a very bad idea.\n\n\n00:56\n(Laughter)\n\n\n00:58\nAround that same time, Stanley Kubrick's \"2001: A Space Odyssey\" came to the theaters, and my life was forever changed. I loved everything about that movie, especially the HAL 9000. Now, HAL was a sentient computer designed to guide the Discovery spacecraft from the Earth to Jupiter. HAL was also a flawed character, for in the end he chose to value the mission over human life. Now, HAL was a fictional character, but nonetheless he speaks to our fears, our fears of being subjugated by some unfeeling, artificial intelligence who is indifferent to our humanity.\n\n\n01:37\nI believe that such fears are unfounded. Indeed, we stand at a remarkable time in human history, where, driven by refusal to accept the limits of our bodies and our minds, we are building machines of exquisite, beautiful complexity and grace that will extend the human experience in ways beyond our imagining.\n\n\n01:59\nAfter a career that led me from the Air Force Academy to Space Command to now, I became a systems engineer, and recently I was drawn into an engineering problem associated with NASA's mission to Mars. Now, in space flights to the Moon, we can rely upon mission control in Houston to watch over all aspects of a flight. However, Mars is 200 times further away, and as a result it takes on average 13 minutes for a signal to travel from the Earth to Mars. If there's trouble, there's not enough time. And so a reasonable engineering solution calls for us to put mission control inside the walls of the Orion spacecraft. Another fascinating idea in the mission profile places humanoid robots on the surface of Mars before the humans themselves arrive, first to build facilities and later to serve as collaborative members of the science team.\n\n\n02:55\nNow, as I looked at this from an engineering perspective, it became very clear to me that what I needed to architect was a smart, collaborative, socially intelligent artificial intelligence. In other words, I needed to build something very much like a HAL but without the homicidal tendencies.\n\n\n03:12\n(Laughter)\n\n\n03:14\nLet's pause for a moment. Is it really possible to build an artificial intelligence like that? Actually, it is. In many ways, this is a hard engineering problem with elements of AI, not some wet hair ball of an AI problem that needs to be engineered. To paraphrase Alan Turing, I'm not interested in building a sentient machine. I'm not building a HAL. All I'm after is a simple brain, something that offers the illusion of intelligence.\n\n\n03:45\nThe art and the science of computing have come a long way since HAL was onscreen, and I'd imagine if his inventor Dr. Chandra were here today, he'd have a whole lot of questions for us. Is it really possible for us to take a system of millions upon millions of devices, to read in their data streams, to predict their failures and act in advance? Yes. Can we build systems that converse with humans in natural language? Yes. Can we build systems that recognize objects, identify emotions, emote themselves, play games and even read lips? Yes. Can we build a system that sets goals, that carries out plans against those goals and learns along the way? Yes. Can we build systems that have a theory of mind? This we are learning to do. Can we build systems that have an ethical and moral foundation? This we must learn how to do. So let's accept for a moment that it's possible to build such an artificial intelligence for this kind of mission and others.\n\n\n04:43\nThe next question you must ask yourself is, should we fear it? Now, every new technology brings with it some measure of trepidation. When we first saw cars, people lamented that we would see the destruction of the family. When we first saw telephones come in, people were worried it would destroy all civil conversation. At a point in time we saw the written word become pervasive, people thought we would lose our ability to memorize. These things are all true to a degree, but it's also the case that these technologies brought to us things that extended the human experience in some profound ways.\n\n\n05:21\nSo let's take this a little further. I do not fear the creation of an AI like this, because it will eventually embody some of our values. Consider this: building a cognitive system is fundamentally different than building a traditional software-intensive system of the past. We don't program them. We teach them. In order to teach a system how to recognize flowers, I show it thousands of flowers of the kinds I like. In order to teach a system how to play a game -- Well, I would. You would, too. I like flowers. Come on. To teach a system how to play a game like Go, I'd have it play thousands of games of Go, but in the process I also teach it how to discern a good game from a bad game. If I want to create an artificially intelligent legal assistant, I will teach it some corpus of law but at the same time I am fusing with it the sense of mercy and justice that is part of that law. In scientific terms, this is what we call ground truth, and here's the important point: in producing these machines, we are therefore teaching them a sense of our values. To that end, I trust an artificial intelligence the same, if not more, as a human who is well-trained.\n\n\n06:36\nBut, you may ask, what about rogue agents, some well-funded nongovernment organization? I do not fear an artificial intelligence in the hand of a lone wolf. Clearly, we cannot protect ourselves against all random acts of violence, but the reality is such a system requires substantial training and subtle training far beyond the resources of an individual. And furthermore, it's far more than just injecting an internet virus to the world, where you push a button, all of a sudden it's in a million places and laptops start blowing up all over the place. Now, these kinds of substances are much larger, and we'll certainly see them coming.\n\n\n07:14\nDo I fear that such an artificial intelligence might threaten all of humanity? If you look at movies such as \"The Matrix,\" \"Metropolis,\" \"The Terminator,\" shows such as \"Westworld,\" they all speak of this kind of fear. Indeed, in the book \"Superintelligence\" by the philosopher Nick Bostrom, he picks up on this theme and observes that a superintelligence might not only be dangerous, it could represent an existential threat to all of humanity. Dr. Bostrom's basic argument is that such systems will eventually have such an insatiable thirst for information that they will perhaps learn how to learn and eventually discover that they may have goals that are contrary to human needs. Dr. Bostrom has a number of followers. He is supported by people such as Elon Musk and Stephen Hawking. With all due respect to these brilliant minds, I believe that they are fundamentally wrong. Now, there are a lot of pieces of Dr. Bostrom's argument to unpack, and I don't have time to unpack them all, but very briefly, consider this: super knowing is very different than super doing. HAL was a threat to the Discovery crew only insofar as HAL commanded all aspects of the Discovery. So it would have to be with a superintelligence. It would have to have dominion over all of our world. This is the stuff of Skynet from the movie \"The Terminator\" in which we had a superintelligence that commanded human will, that directed every device that was in every corner of the world. Practically speaking, it ain't gonna happen. We are not building AIs that control the weather, that direct the tides, that command us capricious, chaotic humans. And furthermore, if such an artificial intelligence existed, it would have to compete with human economies, and thereby compete for resources with us. And in the end -- don't tell Siri this -- we can always unplug them.\n\n\n09:13\n(Laughter)\n\n\n09:17\nWe are on an incredible journey of coevolution with our machines. The humans we are today are not the humans we will be then. To worry now about the rise of a superintelligence is in many ways a dangerous distraction because the rise of computing itself brings to us a number of human and societal issues to which we must now attend. How shall I best organize society when the need for human labor diminishes? How can I bring understanding and education throughout the globe and still respect our differences? How might I extend and enhance human life through cognitive healthcare? How might I use computing to help take us to the stars?\n\n\n10:01\nAnd that's the exciting thing. The opportunities to use computing to advance the human experience are within our reach, here and now, and we are just beginning.\n\n\n10:14\nThank you very much.\n\n\n10:15\n(Applause)\n\n\nExcerpt\n\u00b6\n\n\n\n\nas a result it takes \non average\n 13 minutes for a signal to travel from the Earth to Mars.\n\n\nNow, as I \nlooked at\n this from an engineering perspective, it became very clear to me that what I needed to architect was a smart, collaborative, socially intelligent artificial intelligence. In other words, I needed to build something very much like HAL but without the homicidal tendencies.\n\n\nIn many ways, this is a hard engineering problem with elements of AI, not some \nwet hairball\n of an AI problem that needs to be engineered. (hairball: 1. an obnoxious person \u4e00\u4e2a\u4ee4\u4eba\u8ba8\u538c\u7684\u4eba\uff0c2. exclam. How awful! e.g., Hairball! I did it wrong again! 3. a mess; something difficult or unpleasant. e.g., My life has become a hairball. I can't go on)\n\n\nTo paraphrase Alan Turing, I'm not interested in building a sentient machine. I'm not building a HAL. (To paraphrase Alan Turing: \u5957\u7528alan turing\u7684\u8bdd)\n5.\n\n\n\n\nJune 7, 2018\n\u00b6\n\n\n\n\nbe rooted in something: to be based on something or caused by something (e.g., Most prejudices are rooted in ignorance; Their approaches are rooted in differing interpretations of the meaning of probability == Their approaches are based on differing interpretations...)\n\n\nthe year we took it over: take sth over, \u63a5\u624b\uff0c\u63a5\u7ba1\n\n\nin retrospect: think about a past event or situation, often with different opinion of it from the one you had at the time\n\n\n\n\nJune 9, 2019\n\u00b6\n\n\nWhat AI is -- and isn't\n\u00b6\n\n\nSebastian Thrun and Chris Anderson | TED2017\n\n\nRecommended: \nClick Here for the Video on TED Official Website\n\n\n\n\n\nTranscript\n\u00b6\n\n\n00:12\nChris Anderson: Help us understand what machine learning is, because that seems to be the key driver of so much of the excitement and also of the concern around artificial intelligence. How does machine learning work?\n\n\n00:23\nSebastian Thrun: So, artificial intelligence and machine learning is about 60 years old and has not had a great day in its past until recently. And the reason is that today, we have reached a scale of computing and datasets that was necessary to make machines smart. So here's how it works. If you program a computer today, say, your phone, then you hire software engineers that write a very, very long kitchen recipe, like, \"If the water is too hot, turn down the temperature. If it's too cold, turn up the temperature.\" The recipes are not just 10 lines long. They are millions of lines long. A modern cell phone has 12 million lines of code. A browser has five million lines of code. And each bug in this recipe can cause your computer to crash. That's why a software engineer makes so much money. The new thing now is that computers can find their own rules. So instead of an expert deciphering, step by step, a rule for every contingency, what you do now is you give the computer examples and have it infer its own rules.\n\n\n01:36\nA really good example is AlphaGo, which recently was won by Google. Normally, in game playing, you would really write down all the rules, but in AlphaGo's case, the system looked over a million games and was able to infer its own rules and then beat the world's residing Go champion. That is exciting, because it relieves the software engineer of the need of being super smart, and pushes the burden towards the data. As I said, the inflection point where this has become really possible -- very embarrassing, my thesis was about machine learning. It was completely insignificant, don't read it, because it was 20 years ago and back then, the computers were as big as a cockroach brain. Now they are powerful enough to really emulate kind of specialized human thinking. And then the computers take advantage of the fact that they can look at much more data than people can. So I'd say AlphaGo looked at more than a million games. No human expert can ever study a million games. Google has looked at over a hundred billion web pages. No person can ever study a hundred billion web pages. So as a result, the computer can find rules that even people can't find.\n\n\n02:41\nCA: So instead of looking ahead to, \"If he does that, I will do that,\" it's more saying, \"Here is what looks like a winning pattern, here is what looks like a winning pattern.\"\n\n\n02:50\nST: Yeah. I mean, think about how you raise children. You don't spend the first 18 years giving kids a rule for every contingency and set them free and they have this big program. They stumble, fall, get up, they get slapped or spanked, and they have a positive experience, a good grade in school, and they figure it out on their own. That's happening with computers now, which makes computer programming so much easier all of a sudden. Now we don't have to think anymore. We just give them lots of data.\n\n\n03:14\nCA: And so, this has been key to the spectacular improvement in power of self-driving cars. I think you gave me an example. Can you explain what's happening here?\n\n\n03:25\nST: This is a drive of a self-driving car that we happened to have at Udacity and recently made into a spin-off called Voyage. We have used this thing called deep learning to train a car to drive itself, and this is driving from Mountain View, California, to San Francisco on El Camino Real on a rainy day, with bicyclists and pedestrians and 133 traffic lights. And the novel thing here is, many, many moons ago, I started the Google self-driving car team. And back in the day, I hired the world's best software engineers to find the world's best rules. This is just trained. We drive this road 20 times, we put all this data into the computer brain, and after a few hours of processing, it comes up with behavior that often surpasses human agility. So it's become really easy to program it. This is 100 percent autonomous, about 33 miles, an hour and a half.\n\n\n04:17\nCA: So, explain it -- on the big part of this program on the left, you're seeing basically what the computer sees as trucks and cars and those dots overtaking it and so forth.\n\n\n04:27\nST: On the right side, you see the camera image, which is the main input here, and it's used to find lanes, other cars, traffic lights. The vehicle has a radar to do distance estimation. This is very commonly used in these kind of systems. On the left side you see a laser diagram, where you see obstacles like trees and so on depicted by the laser. But almost all the interesting work is centering on the camera image now. We're really shifting over from precision sensors like radars and lasers into very cheap, commoditized sensors. A camera costs less than eight dollars.\n\n\n04:55\nCA: And that green dot on the left thing, what is that? Is that anything meaningful?\n\n\n04:59\nST: This is a look-ahead point for your adaptive cruise control, so it helps us understand how to regulate velocity based on how far the cars in front of you are.\n\n\n05:08\nCA: And so, you've also got an example, I think, of how the actual learning part takes place. Maybe we can see that. Talk about this.\n\n\n05:15\nST: This is an example where we posed a challenge to Udacity students to take what we call a self-driving car Nanodegree. We gave them this dataset and said \"Hey, can you guys figure out how to steer this car?\" And if you look at the images, it's, even for humans, quite impossible to get the steering right. And we ran a competition and said, \"It's a deep learning competition, AI competition,\" and we gave the students 48 hours. So if you are a software house like Google or Facebook, something like this costs you at least six months of work. So we figured 48 hours is great. And within 48 hours, we got about 100 submissions from students, and the top four got it perfectly right. It drives better than I could drive on this imagery, using deep learning. And again, it's the same methodology. It's this magical thing. When you give enough data to a computer now, and give enough time to comprehend the data, it finds its own rules.\n\n\n06:09\nCA: And so that has led to the development of powerful applications in all sorts of areas. You were talking to me the other day about cancer. Can I show this video?\n\n\n06:19\nST: Yeah, absolutely, please. CA: This is cool.\n\n\n06:22\nST: This is kind of an insight into what's happening in a completely different domain. This is augmenting, or competing -- it's in the eye of the beholder -- with people who are being paid 400,000 dollars a year, dermatologists, highly trained specialists. It takes more than a decade of training to be a good dermatologist. What you see here is the machine learning version of it. It's called a neural network. \"Neural networks\" is the technical term for these machine learning algorithms. They've been around since the 1980s. This one was invented in 1988 by a Facebook Fellow called Yann LeCun, and it propagates data stages through what you could think of as the human brain. It's not quite the same thing, but it emulates the same thing. It goes stage after stage. In the very first stage, it takes the visual input and extracts edges and rods and dots. And the next one becomes more complicated edges and shapes like little half-moons. And eventually, it's able to build really complicated concepts. Andrew Ng has been able to show that it's able to find cat faces and dog faces in vast amounts of images.\n\n\n07:34\nWhat my student team at Stanford has shown is that if you train it on 129,000 images of skin conditions, including melanoma and carcinomas, you can do as good a job as the best human dermatologists. And to convince ourselves that this is the case, we captured an independent dataset that we presented to our network and to 25 board-certified Stanford-level dermatologists, and compared those. And in most cases, they were either on par or above the performance classification accuracy of human dermatologists.\n\n\n08:10\nCA: You were telling me an anecdote. I think about this image right here. What happened here?\n\n\n08:15\nST: This was last Thursday. That's a moving piece. What we've shown before and we published in \"Nature\" earlier this year was this idea that we show dermatologists images and our computer program images, and count how often they're right. But all these images are past images. They've all been biopsied to make sure we had the correct classification. This one wasn't. This one was actually done at Stanford by one of our collaborators. The story goes that our collaborator, who is a world-famous dermatologist, one of the three best, apparently, looked at this mole and said, \"This is not skin cancer.\" And then he had a second moment, where he said, \"Well, let me just check with the app.\" So he took out his iPhone and ran our piece of software, our \"pocket dermatologist,\" so to speak, and the iPhone said: cancer. It said melanoma. And then he was confused. And he decided, \"OK, maybe I trust the iPhone a little bit more than myself,\" and he sent it out to the lab to get it biopsied. And it came up as an aggressive melanoma. So I think this might be the first time that we actually found, in the practice of using deep learning, an actual person whose melanoma would have gone unclassified, had it not been for deep learning.\n\n\n09:24\nCA: I mean, that's incredible.\n\n\n09:26\n(Applause)\n\n\n09:28\nIt feels like there'd be an instant demand for an app like this right now, that you might freak out a lot of people. Are you thinking of doing this, making an app that allows self-checking?\n\n\n09:37\nST: So my in-box is flooded about cancer apps, with heartbreaking stories of people. I mean, some people have had 10, 15, 20 melanomas removed, and are scared that one might be overlooked, like this one, and also, about, I don't know, flying cars and speaker inquiries these days, I guess. My take is, we need more testing. I want to be very careful. It's very easy to give a flashy result and impress a TED audience. It's much harder to put something out that's ethical. And if people were to use the app and choose not to consult the assistance of a doctor because we get it wrong, I would feel really bad about it. So we're currently doing clinical tests, and if these clinical tests commence and our data holds up, we might be able at some point to take this kind of technology and take it out of the Stanford clinic and bring it to the entire world, places where Stanford doctors never, ever set foot.\n\n\n10:30\nCA: And do I hear this right, that it seemed like what you were saying, because you are working with this army of Udacity students, that in a way, you're applying a different form of machine learning than might take place in a company, which is you're combining machine learning with a form of crowd wisdom. Are you saying that sometimes you think that could actually outperform what a company can do, even a vast company?\n\n\n10:53\nST: I believe there's now instances that blow my mind, and I'm still trying to understand. What Chris is referring to is these competitions that we run. We turn them around in 48 hours, and we've been able to build a self-driving car that can drive from Mountain View to San Francisco on surface streets. It's not quite on par with Google after seven years of Google work, but it's getting there. And it took us only two engineers and three months to do this. And the reason is, we have an army of students who participate in competitions. We're not the only ones who use crowdsourcing. Uber and Didi use crowdsource for driving. Airbnb uses crowdsourcing for hotels. There's now many examples where people do bug-finding crowdsourcing or protein folding, of all things, in crowdsourcing. But we've been able to build this car in three months, so I am actually rethinking how we organize corporations.\n\n\n11:47\nWe have a staff of 9,000 people who are never hired, that I never fire. They show up to work and I don't even know. Then they submit to me maybe 9,000 answers. I'm not obliged to use any of those. I end up -- I pay only the winners, so I'm actually very cheapskate here, which is maybe not the best thing to do. But they consider it part of their education, too, which is nice. But these students have been able to produce amazing deep learning results. So yeah, the synthesis of great people and great machine learning is amazing.\n\n\n12:18\nCA: I mean, Gary Kasparov said on the first day [of TED2017] that the winners of chess, surprisingly, turned out to be two amateur chess players with three mediocre-ish, mediocre-to-good, computer programs, that could outperform one grand master with one great chess player, like it was all part of the process. And it almost seems like you're talking about a much richer version of that same idea.\n\n\n12:41\nST: Yeah, I mean, as you followed the fantastic panels yesterday morning, two sessions about AI, robotic overlords and the human response, many, many great things were said. But one of the concerns is that we sometimes confuse what's actually been done with AI with this kind of overlord threat, where your AI develops consciousness, right? The last thing I want is for my AI to have consciousness. I don't want to come into my kitchen and have the refrigerator fall in love with the dishwasher and tell me, because I wasn't nice enough, my food is now warm. I wouldn't buy these products, and I don't want them. But the truth is, for me, AI has always been an augmentation of people. It's been an augmentation of us, to make us stronger. And I think Kasparov was exactly correct. It's been the combination of human smarts and machine smarts that make us stronger. The theme of machines making us stronger is as old as machines are. The agricultural revolution took place because it made steam engines and farming equipment that couldn't farm by itself, that never replaced us; it made us stronger. And I believe this new wave of AI will make us much, much stronger as a human race.\n\n\n13:53\nCA: We'll come on to that a bit more, but just to continue with the scary part of this for some people, like, what feels like it gets scary for people is when you have a computer that can, one, rewrite its own code, so, it can create multiple copies of itself, try a bunch of different code versions, possibly even at random, and then check them out and see if a goal is achieved and improved. So, say the goal is to do better on an intelligence test. You know, a computer that's moderately good at that, you could try a million versions of that. You might find one that was better, and then, you know, repeat. And so the concern is that you get some sort of runaway effect where everything is fine on Thursday evening, and you come back into the lab on Friday morning, and because of the speed of computers and so forth, things have gone crazy, and suddenly --\n\n\n14:45\nST: I would say this is a possibility, but it's a very remote possibility. So let me just translate what I heard you say. In the AlphaGo case, we had exactly this thing: the computer would play the game against itself and then learn new rules. And what machine learning is is a rewriting of the rules. It's the rewriting of code. But I think there was absolutely no concern that AlphaGo would take over the world. It can't even play chess.\n\n\n15:11\nCA: No, no, no, but now, these are all very single-domain things. But it's possible to imagine. I mean, we just saw a computer that seemed nearly capable of passing a university entrance test, that can kind of -- it can't read and understand in the sense that we can, but it can certainly absorb all the text and maybe see increased patterns of meaning. Isn't there a chance that, as this broadens out, there could be a different kind of runaway effect?\n\n\n15:39\nST: That's where I draw the line, honestly. And the chance exists -- I don't want to downplay it -- but I think it's remote, and it's not the thing that's on my mind these days, because I think the big revolution is something else. Everything successful in AI to the present date has been extremely specialized, and it's been thriving on a single idea, which is massive amounts of data. The reason AlphaGo works so well is because of massive numbers of Go plays, and AlphaGo can't drive a car or fly a plane. The Google self-driving car or the Udacity self-driving car thrives on massive amounts of data, and it can't do anything else. It can't even control a motorcycle. It's a very specific, domain-specific function, and the same is true for our cancer app. There has been almost no progress on this thing called \"general AI,\" where you go to an AI and say, \"Hey, invent for me special relativity or string theory.\" It's totally in the infancy.\n\n\n16:32\nThe reason I want to emphasize this, I see the concerns, and I want to acknowledge them. But if I were to think about one thing, I would ask myself the question, \"What if we can take anything repetitive and make ourselves 100 times as efficient?\" It so turns out, 300 years ago, we all worked in agriculture and did farming and did repetitive things. Today, 75 percent of us work in offices and do repetitive things. We've become spreadsheet monkeys. And not just low-end labor. We've become dermatologists doing repetitive things, lawyers doing repetitive things. I think we are at the brink of being able to take an AI, look over our shoulders, and they make us maybe 10 or 50 times as effective in these repetitive things. That's what is on my mind.\n\n\n17:22\nCA: That sounds super exciting. The process of getting there seems a little terrifying to some people, because once a computer can do this repetitive thing much better than the dermatologist or than the driver, especially, is the thing that's talked about so much now, suddenly millions of jobs go, and, you know, the country's in revolution before we ever get to the more glorious aspects of what's possible.\n\n\n17:48\nST: Yeah, and that's an issue, and it's a big issue, and it was pointed out yesterday morning by several guest speakers. Now, prior to me showing up onstage, I confessed I'm a positive, optimistic person, so let me give you an optimistic pitch, which is, think of yourself back 300 years ago. Europe just survived 140 years of continuous war, none of you could read or write, there were no jobs that you hold today, like investment banker or software engineer or TV anchor. We would all be in the fields and farming. Now here comes little Sebastian with a little steam engine in his pocket, saying, \"Hey guys, look at this. It's going to make you 100 times as strong, so you can do something else.\" And then back in the day, there was no real stage, but Chris and I hang out with the cows in the stable, and he says, \"I'm really concerned about it, because I milk my cow every day, and what if the machine does this for me?\"\n\n\n18:43\nThe reason why I mention this is, we're always good in acknowledging past progress and the benefit of it, like our iPhones or our planes or electricity or medical supply. We all love to live to 80, which was impossible 300 years ago. But we kind of don't apply the same rules to the future. So if I look at my own job as a CEO, I would say 90 percent of my work is repetitive, I don't enjoy it, I spend about four hours per day on stupid, repetitive email. And I'm burning to have something that helps me get rid of this. Why? Because I believe all of us are insanely creative; I think the TED community more than anybody else. But even blue-collar workers; I think you can go to your hotel maid and have a drink with him or her, and an hour later, you find a creative idea. What this will empower is to turn this creativity into action. Like, what if you could build Google in a day? What if you could sit over beer and invent the next Snapchat, whatever it is, and tomorrow morning it's up and running?\n\n\n19:49\nAnd that is not science fiction. What's going to happen is, we are already in history. We've unleashed this amazing creativity by de-slaving us from farming and later, of course, from factory work and have invented so many things. It's going to be even better, in my opinion. And there's going to be great side effects. One of the side effects will be that things like food and medical supply and education and shelter and transportation will all become much more affordable to all of us, not just the rich people.\n\n\n20:22\nCA: Hmm. So when Martin Ford argued, you know, that this time it's different because the intelligence that we've used in the past to find new ways to be will be matched at the same pace by computers taking over those things, what I hear you saying is that, not completely, because of human creativity. Do you think that that's fundamentally different from the kind of creativity that computers can do?\n\n\n20:50\nST: So, that's my firm belief as an AI person -- that I haven't seen any real progress on creativity and out-of-the-box thinking. What I see right now -- and this is really important for people to realize, because the word \"artificial intelligence\" is so threatening, and then we have Steve Spielberg tossing a movie in, where all of a sudden the computer is our overlord, but it's really a technology. It's a technology that helps us do repetitive things. And the progress has been entirely on the repetitive end. It's been in legal document discovery. It's been contract drafting. It's been screening X-rays of your chest. And these things are so specialized, I don't see the big threat of humanity. In fact, we as people -- I mean, let's face it: we've become superhuman. We've made us superhuman. We can swim across the Atlantic in 11 hours. We can take a device out of our pocket and shout all the way to Australia, and in real time, have that person shouting back to us. That's physically not possible. We're breaking the rules of physics. When this is said and done, we're going to remember everything we've ever said and seen, you'll remember every person, which is good for me in my early stages of Alzheimer's. Sorry, what was I saying? I forgot.\n\n\n22:02\nCA: (Laughs)\n\n\n22:03\nST: We will probably have an IQ of 1,000 or more. There will be no more spelling classes for our kids, because there's no spelling issue anymore. There's no math issue anymore. And I think what really will happen is that we can be super creative. And we are. We are creative. That's our secret weapon.\n\n\n22:21\nCA: So the jobs that are getting lost, in a way, even though it's going to be painful, humans are capable of more than those jobs. This is the dream. The dream is that humans can rise to just a new level of empowerment and discovery. That's the dream.\n\n\n22:36\nST: And think about this: if you look at the history of humanity, that might be whatever -- 60-100,000 years old, give or take -- almost everything that you cherish in terms of invention, of technology, of things we've built, has been invented in the last 150 years. If you toss in the book and the wheel, it's a little bit older. Or the axe. But your phone, your sneakers, these chairs, modern manufacturing, penicillin -- the things we cherish. Now, that to me means the next 150 years will find more things. In fact, the pace of invention has gone up, not gone down, in my opinion. I believe only one percent of interesting things have been invented yet. Right? We haven't cured cancer. We don't have flying cars -- yet. Hopefully, I'll change this. That used to be an example people laughed about. (Laughs) It's funny, isn't it? Working secretly on flying cars. We don't live twice as long yet. OK? We don't have this magic implant in our brain that gives us the information we want. And you might be appalled by it, but I promise you, once you have it, you'll love it. I hope you will. It's a bit scary, I know.\n\n\n23:48\nThere are so many things we haven't invented yet that I think we'll invent. We have no gravity shields. We can't beam ourselves from one location to another. That sounds ridiculous, but about 200 years ago, experts were of the opinion that flight wouldn't exist, even 120 years ago, and if you moved faster than you could run, you would instantly die. So who says we are correct today that you can't beam a person from here to Mars?\n\n\n24:12\nCA: Sebastian, thank you so much for your incredibly inspiring vision and your brilliance. Thank you, Sebastian Thrun. That was fantastic. (Applause)\n\n\nExcerpt\n\u00b6\n\n\n1.\n\n\nPhrases\n\u00b6\n\n\n\n\n\n\non and off: intermittently, from time to time, now and again, e.g., it rained on and off most of the afternoon.\n\n\n\n\n\n\nintermittently: in an way that starts and stops often over a period of time; not regularly, e.g., Protests continued intermittently throughout November.",
            "title": "June"
        },
        {
            "location": "/2018/06/#june-4-2018",
            "text": "",
            "title": "June 4, 2018"
        },
        {
            "location": "/2018/06/#quote-of-the-day",
            "text": "Teach self-denial and make its practice pleasure, and you can create for the world a destiny more sublime that ever issued from the brain of the wildest dreamer. -- Sir Walter Scott   Meaning: This quote seems overstated and exaggerated, although it has some truth to it. \"Self-denial \" is  harsh-sounding  but means self-restraint or holding back on one's selfish desires in favor of caring about others. Sometimes you to have to deny yourself some selfish satisfaction in order to see to the welfare of other people. The writer of the quote believes that if people were taught to put others before themselves and,  moreover , to enjoy  the virtue of altruism , the world would be a wonderful place, in a way we can hardly imagine. It is no doubt true that giving up self-interest in favor of altruism would make a better world. But the way this idea is stated with  such an excessive tone  to me makes it a little weird. It could have been stated more clearly and more effectively by a better writer.  Source   People often overestimate what will happen in the next two years and underestimate what will happen in ten. -- Bill Gates",
            "title": "Quote of the Day"
        },
        {
            "location": "/2018/06/#phrase",
            "text": "see eye to eye : be in full agreement.   Eg: The boss and I do not always see eye to eye.",
            "title": "Phrase"
        },
        {
            "location": "/2018/06/#ted-how-to-turn-a-group-of-strangers-into-a-team",
            "text": "Amy Edmondson  Recommended:  Click Here for the Video on TED Official Website",
            "title": "TED - How to turn a group of strangers into a team"
        },
        {
            "location": "/2018/06/#transcript",
            "text": "00:12\nIt's August 5, 2010. A massive collapse at the San Jos\u00e9 Copper Mine in Northern Chile has left 33 men trapped half a mile -- that's two Empire State Buildings -- below some of the hardest rock in the world. They will find their way to a small refuge designed for this purpose, where they will find intense heat, filth and about enough food for two men for 10 days. Aboveground, it doesn't take long for the experts to figure out that there is no solution. No drilling technology in the industry is capable of getting through rock that hard and that deep fast enough to save their lives. It's not exactly clear where the refuge is. It's not even clear if the miners are alive. And it's not even clear who's in charge. Yet, within 70 days, all 33 of these men will be brought to the surface alive. This remarkable story is a case study in the power of teaming.  01:24\nSo what's \"teaming\"? Teaming is teamwork on the fly. It's coordinating and collaborating with people across boundaries of all kinds -- expertise, distance, time zone, you name it -- to get work done.  01:39\nThink of your favorite sports team, because this is different. Sports teams work together: that magic, those game-saving plays. Now, sports teams win because they practice. But you can only practice if you have the same members over time. And so you can think of teaming ... Sports teams embody the definition of a team, the formal definition. It's a stable, bounded, reasonably small group of people who are interdependent in achieving a shared outcome. You can think of teaming as a kind of pickup game in the park, in contrast to the formal, well-practiced team. Now, which one is going to win in a playoff? The answer is obvious. So why do I study teaming? It's because it's the way more and more of us have to work today. With 24/7 global fast-paced operations, crazy shifting schedules and ever-narrower expertise, more and more of us have to work with different people all the time to get our work done. We don't have the luxury of stable teams. Now, when you can have that luxury, by all means do it. But increasingly for a lot of the work we do today, we don't have that option. One place where this is true is hospitals. This is where I've done a lot of my research over the years. So it turns out hospitals have to be open 24/7. And patients -- well, they're all different. They're all different in complicated and unique ways. The average hospitalized patient is seen by 60 or so different caregivers throughout his stay. They come from different shifts, different specialties, different areas of expertise, and they may not even know each other's name. But they have to coordinate in order for the patient to get great care. And when they don't, the results can be tragic.  03:36\nOf course, in teaming, the stakes aren't always life and death. Consider what it takes to create an animated film, an award-winning animated film. I had the good fortune to go to Disney Animation and study over 900 scientists, artists, storytellers, computer scientists as they teamed up in constantly changing configurations to create amazing outcomes like \"Frozen.\" They just work together, and never the same group twice, not knowing what's going to happen next. Now, taking care of patients in the emergency room and designing an animated film are obviously very different work. Yet underneath the differences, they have a lot in common. You have to get different expertise at different times, you don't have fixed roles, you don't have fixed deliverables, you're going to be doing a lot of things that have never been done before, and you can't do it in a stable team.  04:36\nNow, this way of working isn't easy, but as I said, it's more and more the way many of us have to work, so we have to understand it. And I would argue that it's especially needed for work that's complex and unpredictable and for solving big problems. Paul Polman, the Unilever CEO, put this really well when he said, \"The issues we face today are so big and so challenging, it becomes quite clear we can't do it alone, and so there is a certain humility in knowing you have to invite people in.\" Issues like food or water scarcity cannot be done by individuals, even by single companies, even by single sectors. So we're reaching out to team across big teaming, grand-scale teaming.  05:24\nTake the quest for smart cities. Maybe you've seen some of the rhetoric: mixed-use designs, zero net energy buildings, smart mobility, green, livable, wonderful cities. We have the vocabulary, we have the visions, not to mention the need. We have the technology. Two megatrends -- urbanization, we're fast becoming a more urban planet, and climate change -- have been increasingly pointing to cities as a crucial target for innovation. And now around the world in various locations, people have been teaming up to design and try to create green, livable, smart cities. It's a massive innovation challenge.  06:09\nTo understand it better, I studied a start-up -- a smart-city software start-up -- as it teamed up with a real estate developer, some civil engineers, a mayor, an architect, some builders, some tech companies. Their goal was to build a demo smart city from scratch. OK. Five years into the project, not a whole lot had happened. Six years, still no ground broken. It seemed that teaming across industry boundaries was really, really hard. OK, so ... We had inadvertently discovered what I call \"professional culture clash\" with this project. You know, software engineers and real estate developers think differently -- really differently: different values, different time frames -- time frames is a big one -- and different jargon, different language. And so they don't always see eye to eye. I think this is a bigger problem than most of us realize. In fact, I think professional culture clash is a major barrier to building the future that we aspire to build. And so it becomes a problem that we have to understand, a problem that we have to figure out how to crack. So how do you make sure teaming goes well, especially big teaming? This is the question I've been trying to solve for a number of years in many different workplaces with my research.  07:46\nNow, to begin to get just a glimpse of the answer to this question, let's go back to Chile. In Chile, we witnessed 10 weeks of teaming by hundreds of individuals from different professions, different companies, different sectors, even different nations. And as this process unfolded, they had lots of ideas, they tried many things, they experimented, they failed, they experienced devastating daily failure, but they picked up, persevered, and went on forward. And really, what we witnessed there was they were able to be humble in the face of the very real challenge ahead, curious -- all of these diverse individuals, diverse expertise especially, nationality as well, were quite curious about what each other brings. And they were willing to take risks to learn fast what might work. And ultimately, 17 days into this remarkable story, ideas came from everywhere. They came from Andr\u00e9 Sougarret, who is a brilliant mining engineer who was appointed by the government to lead the rescue. They came from NASA. They came from Chilean Special Forces. They came from volunteers around the world. And while many of us, including myself, watched from afar, these folks made slow, painful progress through the rock.  09:14\nOn the 17 th  day, they broke through to the refuge. It's just a remarkable moment. And with just a very small incision, they were able to find it through a bunch of experimental techniques. And then for the next 53 days, that narrow lifeline would be the path where food and medicine and communication would travel, while aboveground, for 53 more days, they continued the teaming to find a way to create a much larger hole and also to design a capsule. This is the capsule. And then on the 69 th  day, over 22 painstaking hours, they managed to pull the miners out one by one.  09:59\nSo how did they overcome professional culture clash? I would say in a word, it's leadership, but let me be more specific. When teaming works, you can be sure that some leaders, leaders at all levels, have been crystal clear that they don't have the answers. Let's call this \"situational humility.\" It's appropriate humility. We don't know how to do it. You can be sure, as I said before, people were very curious, and this situational humility combined with curiosity creates a sense of psychological safety that allows you take risks with strangers, because let's face it: it's hard to speak up, right? It's hard to ask for help. It's hard to offer an idea that might be a stupid idea if you don't know people very well. You need psychological safety to do that. They overcame what I like to call the basic human challenge: it's hard to learn if you already know. And unfortunately, we're hardwired to think we know. And so we've got to remind ourselves -- and we can do it -- to be curious; to be curious about what others bring. And that curiosity can also spawn a kind of generosity of interpretation.  11:11\nBut there's another barrier, and you all know it. You wouldn't be in this room if you didn't know it. And to explain it, I'm going to quote from the movie \"The Paper Chase.\" This, by the way, is what Hollywood thinks a Harvard professor is supposed to look like. You be the judge. The professor in this famous scene, he's welcoming the new 1L class, and he says, \"Look to your left. Look to your right. one of you won't be here next year.\" What message did they hear? \"It's me or you.\" For me to succeed, you must fail. Now, I don't think too many organizations welcome newcomers that way anymore, but still, many times people arrive with that message of scarcity anyway. It's me or you. It's awfully hard to team if you inadvertently see others as competitors.  11:57\nSo we have to overcome that one as well, and when we do, the results can be awesome. Abraham Lincoln said once, \"I don't like that man very much. I must get to know him better.\" Think about that -- I don't like him, that means I don't know him well enough. It's extraordinary. This is the mindset, I have to say, this is the mindset you need for effective teaming. In our silos, we can get things done. But when we step back and reach out and reach across, miracles can happen. Miners can be rescued, patients can be saved, beautiful films can be created.  12:36\nTo get there, I think there's no better advice than this: look to your left, look to your right. How quickly can you find the unique talents, skills and hopes of your neighbor, and how quickly, in turn, can you convey what you bring? Because for us to team up to build the future we know we can create that none of us can do alone, that's the mindset we need.  12:59\nThank you.  13:01\n(Applause)",
            "title": "Transcript"
        },
        {
            "location": "/2018/06/#excerpt",
            "text": "a massive collapse: \u91cd\u5927\u574d\u584c  left 33 men trapped half a mile below  some of the hardest rock  in the world  find a small  refuge  designed for this purpose: refuge is a shelter or protection from danger, trouble, etc.  filth : any very dirty and unpleasant substance -- \ne.g. The floor was covered in  grease  and filth. -- \ngrease: any thick oil substance, especially one that is used to make machines run smoothly.  Aboveground, it doesn't take long for the experts to figures out that there is no solution.  It's not exactly clear where the refuge is. \nIt's not even clear if the miners are alive. \nAnd it's not even clear who's in charge.  Teaming is  teamwork on the fly :  on the fly  means quickly and informally, without thought or preparation. Actually this idiom has so many meanings, here the meaning should be  if you do something on the fly, you do it quickly, without thinking about it  or planning it in advance. . E.g. make decisions on the fly.  you name it : whatever you can think of (used to express the extent or variety of something) -- It's coordinating and collaborating with people  across boundaries of all kinds  -- expertise, distance, time zone,  you name it  -- to get work done.  Now, sports teams win because they practice. But you can only practice if you have the same members  over time .  embody: 1. to express or represent an idea or a quality: embody something, e.g. a politician who embodies the hopes of black youth. -- 2. embody something (formal): to include or contain something: e.g. this model embodies many new features.  pickup: adj, to be used only before noun, (of a sports team) often not planned in advance and that anyone who wants to can join in.",
            "title": "Excerpt"
        },
        {
            "location": "/2018/06/#june-6-2018",
            "text": "",
            "title": "June 6, 2018"
        },
        {
            "location": "/2018/06/#ted-dont-fear-superintelligent-ai",
            "text": "Grady Booch  Recommended:  Click Here for the Video on TED Official Website   00:12\nWhen I was a kid, I was the quintessential nerd. I think some of you were, too.  00:19\n(Laughter)  00:20\nAnd you, sir, who laughed the loudest, you probably still are.  00:24\n(Laughter)  00:26\nI grew up in a small town in the dusty plains of north Texas, the son of a sheriff who was the son of a pastor. Getting into trouble was not an option. And so I started reading calculus books for fun.  00:39\n(Laughter)  00:40\nYou did, too. That led me to building a laser and a computer and model rockets, and that led me to making rocket fuel in my bedroom. Now, in scientific terms, we call this a very bad idea.  00:56\n(Laughter)  00:58\nAround that same time, Stanley Kubrick's \"2001: A Space Odyssey\" came to the theaters, and my life was forever changed. I loved everything about that movie, especially the HAL 9000. Now, HAL was a sentient computer designed to guide the Discovery spacecraft from the Earth to Jupiter. HAL was also a flawed character, for in the end he chose to value the mission over human life. Now, HAL was a fictional character, but nonetheless he speaks to our fears, our fears of being subjugated by some unfeeling, artificial intelligence who is indifferent to our humanity.  01:37\nI believe that such fears are unfounded. Indeed, we stand at a remarkable time in human history, where, driven by refusal to accept the limits of our bodies and our minds, we are building machines of exquisite, beautiful complexity and grace that will extend the human experience in ways beyond our imagining.  01:59\nAfter a career that led me from the Air Force Academy to Space Command to now, I became a systems engineer, and recently I was drawn into an engineering problem associated with NASA's mission to Mars. Now, in space flights to the Moon, we can rely upon mission control in Houston to watch over all aspects of a flight. However, Mars is 200 times further away, and as a result it takes on average 13 minutes for a signal to travel from the Earth to Mars. If there's trouble, there's not enough time. And so a reasonable engineering solution calls for us to put mission control inside the walls of the Orion spacecraft. Another fascinating idea in the mission profile places humanoid robots on the surface of Mars before the humans themselves arrive, first to build facilities and later to serve as collaborative members of the science team.  02:55\nNow, as I looked at this from an engineering perspective, it became very clear to me that what I needed to architect was a smart, collaborative, socially intelligent artificial intelligence. In other words, I needed to build something very much like a HAL but without the homicidal tendencies.  03:12\n(Laughter)  03:14\nLet's pause for a moment. Is it really possible to build an artificial intelligence like that? Actually, it is. In many ways, this is a hard engineering problem with elements of AI, not some wet hair ball of an AI problem that needs to be engineered. To paraphrase Alan Turing, I'm not interested in building a sentient machine. I'm not building a HAL. All I'm after is a simple brain, something that offers the illusion of intelligence.  03:45\nThe art and the science of computing have come a long way since HAL was onscreen, and I'd imagine if his inventor Dr. Chandra were here today, he'd have a whole lot of questions for us. Is it really possible for us to take a system of millions upon millions of devices, to read in their data streams, to predict their failures and act in advance? Yes. Can we build systems that converse with humans in natural language? Yes. Can we build systems that recognize objects, identify emotions, emote themselves, play games and even read lips? Yes. Can we build a system that sets goals, that carries out plans against those goals and learns along the way? Yes. Can we build systems that have a theory of mind? This we are learning to do. Can we build systems that have an ethical and moral foundation? This we must learn how to do. So let's accept for a moment that it's possible to build such an artificial intelligence for this kind of mission and others.  04:43\nThe next question you must ask yourself is, should we fear it? Now, every new technology brings with it some measure of trepidation. When we first saw cars, people lamented that we would see the destruction of the family. When we first saw telephones come in, people were worried it would destroy all civil conversation. At a point in time we saw the written word become pervasive, people thought we would lose our ability to memorize. These things are all true to a degree, but it's also the case that these technologies brought to us things that extended the human experience in some profound ways.  05:21\nSo let's take this a little further. I do not fear the creation of an AI like this, because it will eventually embody some of our values. Consider this: building a cognitive system is fundamentally different than building a traditional software-intensive system of the past. We don't program them. We teach them. In order to teach a system how to recognize flowers, I show it thousands of flowers of the kinds I like. In order to teach a system how to play a game -- Well, I would. You would, too. I like flowers. Come on. To teach a system how to play a game like Go, I'd have it play thousands of games of Go, but in the process I also teach it how to discern a good game from a bad game. If I want to create an artificially intelligent legal assistant, I will teach it some corpus of law but at the same time I am fusing with it the sense of mercy and justice that is part of that law. In scientific terms, this is what we call ground truth, and here's the important point: in producing these machines, we are therefore teaching them a sense of our values. To that end, I trust an artificial intelligence the same, if not more, as a human who is well-trained.  06:36\nBut, you may ask, what about rogue agents, some well-funded nongovernment organization? I do not fear an artificial intelligence in the hand of a lone wolf. Clearly, we cannot protect ourselves against all random acts of violence, but the reality is such a system requires substantial training and subtle training far beyond the resources of an individual. And furthermore, it's far more than just injecting an internet virus to the world, where you push a button, all of a sudden it's in a million places and laptops start blowing up all over the place. Now, these kinds of substances are much larger, and we'll certainly see them coming.  07:14\nDo I fear that such an artificial intelligence might threaten all of humanity? If you look at movies such as \"The Matrix,\" \"Metropolis,\" \"The Terminator,\" shows such as \"Westworld,\" they all speak of this kind of fear. Indeed, in the book \"Superintelligence\" by the philosopher Nick Bostrom, he picks up on this theme and observes that a superintelligence might not only be dangerous, it could represent an existential threat to all of humanity. Dr. Bostrom's basic argument is that such systems will eventually have such an insatiable thirst for information that they will perhaps learn how to learn and eventually discover that they may have goals that are contrary to human needs. Dr. Bostrom has a number of followers. He is supported by people such as Elon Musk and Stephen Hawking. With all due respect to these brilliant minds, I believe that they are fundamentally wrong. Now, there are a lot of pieces of Dr. Bostrom's argument to unpack, and I don't have time to unpack them all, but very briefly, consider this: super knowing is very different than super doing. HAL was a threat to the Discovery crew only insofar as HAL commanded all aspects of the Discovery. So it would have to be with a superintelligence. It would have to have dominion over all of our world. This is the stuff of Skynet from the movie \"The Terminator\" in which we had a superintelligence that commanded human will, that directed every device that was in every corner of the world. Practically speaking, it ain't gonna happen. We are not building AIs that control the weather, that direct the tides, that command us capricious, chaotic humans. And furthermore, if such an artificial intelligence existed, it would have to compete with human economies, and thereby compete for resources with us. And in the end -- don't tell Siri this -- we can always unplug them.  09:13\n(Laughter)  09:17\nWe are on an incredible journey of coevolution with our machines. The humans we are today are not the humans we will be then. To worry now about the rise of a superintelligence is in many ways a dangerous distraction because the rise of computing itself brings to us a number of human and societal issues to which we must now attend. How shall I best organize society when the need for human labor diminishes? How can I bring understanding and education throughout the globe and still respect our differences? How might I extend and enhance human life through cognitive healthcare? How might I use computing to help take us to the stars?  10:01\nAnd that's the exciting thing. The opportunities to use computing to advance the human experience are within our reach, here and now, and we are just beginning.  10:14\nThank you very much.  10:15\n(Applause)",
            "title": "TED - Don't fear superintelligent AI"
        },
        {
            "location": "/2018/06/#excerpt_1",
            "text": "as a result it takes  on average  13 minutes for a signal to travel from the Earth to Mars.  Now, as I  looked at  this from an engineering perspective, it became very clear to me that what I needed to architect was a smart, collaborative, socially intelligent artificial intelligence. In other words, I needed to build something very much like HAL but without the homicidal tendencies.  In many ways, this is a hard engineering problem with elements of AI, not some  wet hairball  of an AI problem that needs to be engineered. (hairball: 1. an obnoxious person \u4e00\u4e2a\u4ee4\u4eba\u8ba8\u538c\u7684\u4eba\uff0c2. exclam. How awful! e.g., Hairball! I did it wrong again! 3. a mess; something difficult or unpleasant. e.g., My life has become a hairball. I can't go on)  To paraphrase Alan Turing, I'm not interested in building a sentient machine. I'm not building a HAL. (To paraphrase Alan Turing: \u5957\u7528alan turing\u7684\u8bdd)\n5.",
            "title": "Excerpt"
        },
        {
            "location": "/2018/06/#june-7-2018",
            "text": "be rooted in something: to be based on something or caused by something (e.g., Most prejudices are rooted in ignorance; Their approaches are rooted in differing interpretations of the meaning of probability == Their approaches are based on differing interpretations...)  the year we took it over: take sth over, \u63a5\u624b\uff0c\u63a5\u7ba1  in retrospect: think about a past event or situation, often with different opinion of it from the one you had at the time",
            "title": "June 7, 2018"
        },
        {
            "location": "/2018/06/#june-9-2019",
            "text": "",
            "title": "June 9, 2019"
        },
        {
            "location": "/2018/06/#what-ai-is-and-isnt",
            "text": "Sebastian Thrun and Chris Anderson | TED2017  Recommended:  Click Here for the Video on TED Official Website",
            "title": "What AI is -- and isn't"
        },
        {
            "location": "/2018/06/#transcript_1",
            "text": "00:12\nChris Anderson: Help us understand what machine learning is, because that seems to be the key driver of so much of the excitement and also of the concern around artificial intelligence. How does machine learning work?  00:23\nSebastian Thrun: So, artificial intelligence and machine learning is about 60 years old and has not had a great day in its past until recently. And the reason is that today, we have reached a scale of computing and datasets that was necessary to make machines smart. So here's how it works. If you program a computer today, say, your phone, then you hire software engineers that write a very, very long kitchen recipe, like, \"If the water is too hot, turn down the temperature. If it's too cold, turn up the temperature.\" The recipes are not just 10 lines long. They are millions of lines long. A modern cell phone has 12 million lines of code. A browser has five million lines of code. And each bug in this recipe can cause your computer to crash. That's why a software engineer makes so much money. The new thing now is that computers can find their own rules. So instead of an expert deciphering, step by step, a rule for every contingency, what you do now is you give the computer examples and have it infer its own rules.  01:36\nA really good example is AlphaGo, which recently was won by Google. Normally, in game playing, you would really write down all the rules, but in AlphaGo's case, the system looked over a million games and was able to infer its own rules and then beat the world's residing Go champion. That is exciting, because it relieves the software engineer of the need of being super smart, and pushes the burden towards the data. As I said, the inflection point where this has become really possible -- very embarrassing, my thesis was about machine learning. It was completely insignificant, don't read it, because it was 20 years ago and back then, the computers were as big as a cockroach brain. Now they are powerful enough to really emulate kind of specialized human thinking. And then the computers take advantage of the fact that they can look at much more data than people can. So I'd say AlphaGo looked at more than a million games. No human expert can ever study a million games. Google has looked at over a hundred billion web pages. No person can ever study a hundred billion web pages. So as a result, the computer can find rules that even people can't find.  02:41\nCA: So instead of looking ahead to, \"If he does that, I will do that,\" it's more saying, \"Here is what looks like a winning pattern, here is what looks like a winning pattern.\"  02:50\nST: Yeah. I mean, think about how you raise children. You don't spend the first 18 years giving kids a rule for every contingency and set them free and they have this big program. They stumble, fall, get up, they get slapped or spanked, and they have a positive experience, a good grade in school, and they figure it out on their own. That's happening with computers now, which makes computer programming so much easier all of a sudden. Now we don't have to think anymore. We just give them lots of data.  03:14\nCA: And so, this has been key to the spectacular improvement in power of self-driving cars. I think you gave me an example. Can you explain what's happening here?  03:25\nST: This is a drive of a self-driving car that we happened to have at Udacity and recently made into a spin-off called Voyage. We have used this thing called deep learning to train a car to drive itself, and this is driving from Mountain View, California, to San Francisco on El Camino Real on a rainy day, with bicyclists and pedestrians and 133 traffic lights. And the novel thing here is, many, many moons ago, I started the Google self-driving car team. And back in the day, I hired the world's best software engineers to find the world's best rules. This is just trained. We drive this road 20 times, we put all this data into the computer brain, and after a few hours of processing, it comes up with behavior that often surpasses human agility. So it's become really easy to program it. This is 100 percent autonomous, about 33 miles, an hour and a half.  04:17\nCA: So, explain it -- on the big part of this program on the left, you're seeing basically what the computer sees as trucks and cars and those dots overtaking it and so forth.  04:27\nST: On the right side, you see the camera image, which is the main input here, and it's used to find lanes, other cars, traffic lights. The vehicle has a radar to do distance estimation. This is very commonly used in these kind of systems. On the left side you see a laser diagram, where you see obstacles like trees and so on depicted by the laser. But almost all the interesting work is centering on the camera image now. We're really shifting over from precision sensors like radars and lasers into very cheap, commoditized sensors. A camera costs less than eight dollars.  04:55\nCA: And that green dot on the left thing, what is that? Is that anything meaningful?  04:59\nST: This is a look-ahead point for your adaptive cruise control, so it helps us understand how to regulate velocity based on how far the cars in front of you are.  05:08\nCA: And so, you've also got an example, I think, of how the actual learning part takes place. Maybe we can see that. Talk about this.  05:15\nST: This is an example where we posed a challenge to Udacity students to take what we call a self-driving car Nanodegree. We gave them this dataset and said \"Hey, can you guys figure out how to steer this car?\" And if you look at the images, it's, even for humans, quite impossible to get the steering right. And we ran a competition and said, \"It's a deep learning competition, AI competition,\" and we gave the students 48 hours. So if you are a software house like Google or Facebook, something like this costs you at least six months of work. So we figured 48 hours is great. And within 48 hours, we got about 100 submissions from students, and the top four got it perfectly right. It drives better than I could drive on this imagery, using deep learning. And again, it's the same methodology. It's this magical thing. When you give enough data to a computer now, and give enough time to comprehend the data, it finds its own rules.  06:09\nCA: And so that has led to the development of powerful applications in all sorts of areas. You were talking to me the other day about cancer. Can I show this video?  06:19\nST: Yeah, absolutely, please. CA: This is cool.  06:22\nST: This is kind of an insight into what's happening in a completely different domain. This is augmenting, or competing -- it's in the eye of the beholder -- with people who are being paid 400,000 dollars a year, dermatologists, highly trained specialists. It takes more than a decade of training to be a good dermatologist. What you see here is the machine learning version of it. It's called a neural network. \"Neural networks\" is the technical term for these machine learning algorithms. They've been around since the 1980s. This one was invented in 1988 by a Facebook Fellow called Yann LeCun, and it propagates data stages through what you could think of as the human brain. It's not quite the same thing, but it emulates the same thing. It goes stage after stage. In the very first stage, it takes the visual input and extracts edges and rods and dots. And the next one becomes more complicated edges and shapes like little half-moons. And eventually, it's able to build really complicated concepts. Andrew Ng has been able to show that it's able to find cat faces and dog faces in vast amounts of images.  07:34\nWhat my student team at Stanford has shown is that if you train it on 129,000 images of skin conditions, including melanoma and carcinomas, you can do as good a job as the best human dermatologists. And to convince ourselves that this is the case, we captured an independent dataset that we presented to our network and to 25 board-certified Stanford-level dermatologists, and compared those. And in most cases, they were either on par or above the performance classification accuracy of human dermatologists.  08:10\nCA: You were telling me an anecdote. I think about this image right here. What happened here?  08:15\nST: This was last Thursday. That's a moving piece. What we've shown before and we published in \"Nature\" earlier this year was this idea that we show dermatologists images and our computer program images, and count how often they're right. But all these images are past images. They've all been biopsied to make sure we had the correct classification. This one wasn't. This one was actually done at Stanford by one of our collaborators. The story goes that our collaborator, who is a world-famous dermatologist, one of the three best, apparently, looked at this mole and said, \"This is not skin cancer.\" And then he had a second moment, where he said, \"Well, let me just check with the app.\" So he took out his iPhone and ran our piece of software, our \"pocket dermatologist,\" so to speak, and the iPhone said: cancer. It said melanoma. And then he was confused. And he decided, \"OK, maybe I trust the iPhone a little bit more than myself,\" and he sent it out to the lab to get it biopsied. And it came up as an aggressive melanoma. So I think this might be the first time that we actually found, in the practice of using deep learning, an actual person whose melanoma would have gone unclassified, had it not been for deep learning.  09:24\nCA: I mean, that's incredible.  09:26\n(Applause)  09:28\nIt feels like there'd be an instant demand for an app like this right now, that you might freak out a lot of people. Are you thinking of doing this, making an app that allows self-checking?  09:37\nST: So my in-box is flooded about cancer apps, with heartbreaking stories of people. I mean, some people have had 10, 15, 20 melanomas removed, and are scared that one might be overlooked, like this one, and also, about, I don't know, flying cars and speaker inquiries these days, I guess. My take is, we need more testing. I want to be very careful. It's very easy to give a flashy result and impress a TED audience. It's much harder to put something out that's ethical. And if people were to use the app and choose not to consult the assistance of a doctor because we get it wrong, I would feel really bad about it. So we're currently doing clinical tests, and if these clinical tests commence and our data holds up, we might be able at some point to take this kind of technology and take it out of the Stanford clinic and bring it to the entire world, places where Stanford doctors never, ever set foot.  10:30\nCA: And do I hear this right, that it seemed like what you were saying, because you are working with this army of Udacity students, that in a way, you're applying a different form of machine learning than might take place in a company, which is you're combining machine learning with a form of crowd wisdom. Are you saying that sometimes you think that could actually outperform what a company can do, even a vast company?  10:53\nST: I believe there's now instances that blow my mind, and I'm still trying to understand. What Chris is referring to is these competitions that we run. We turn them around in 48 hours, and we've been able to build a self-driving car that can drive from Mountain View to San Francisco on surface streets. It's not quite on par with Google after seven years of Google work, but it's getting there. And it took us only two engineers and three months to do this. And the reason is, we have an army of students who participate in competitions. We're not the only ones who use crowdsourcing. Uber and Didi use crowdsource for driving. Airbnb uses crowdsourcing for hotels. There's now many examples where people do bug-finding crowdsourcing or protein folding, of all things, in crowdsourcing. But we've been able to build this car in three months, so I am actually rethinking how we organize corporations.  11:47\nWe have a staff of 9,000 people who are never hired, that I never fire. They show up to work and I don't even know. Then they submit to me maybe 9,000 answers. I'm not obliged to use any of those. I end up -- I pay only the winners, so I'm actually very cheapskate here, which is maybe not the best thing to do. But they consider it part of their education, too, which is nice. But these students have been able to produce amazing deep learning results. So yeah, the synthesis of great people and great machine learning is amazing.  12:18\nCA: I mean, Gary Kasparov said on the first day [of TED2017] that the winners of chess, surprisingly, turned out to be two amateur chess players with three mediocre-ish, mediocre-to-good, computer programs, that could outperform one grand master with one great chess player, like it was all part of the process. And it almost seems like you're talking about a much richer version of that same idea.  12:41\nST: Yeah, I mean, as you followed the fantastic panels yesterday morning, two sessions about AI, robotic overlords and the human response, many, many great things were said. But one of the concerns is that we sometimes confuse what's actually been done with AI with this kind of overlord threat, where your AI develops consciousness, right? The last thing I want is for my AI to have consciousness. I don't want to come into my kitchen and have the refrigerator fall in love with the dishwasher and tell me, because I wasn't nice enough, my food is now warm. I wouldn't buy these products, and I don't want them. But the truth is, for me, AI has always been an augmentation of people. It's been an augmentation of us, to make us stronger. And I think Kasparov was exactly correct. It's been the combination of human smarts and machine smarts that make us stronger. The theme of machines making us stronger is as old as machines are. The agricultural revolution took place because it made steam engines and farming equipment that couldn't farm by itself, that never replaced us; it made us stronger. And I believe this new wave of AI will make us much, much stronger as a human race.  13:53\nCA: We'll come on to that a bit more, but just to continue with the scary part of this for some people, like, what feels like it gets scary for people is when you have a computer that can, one, rewrite its own code, so, it can create multiple copies of itself, try a bunch of different code versions, possibly even at random, and then check them out and see if a goal is achieved and improved. So, say the goal is to do better on an intelligence test. You know, a computer that's moderately good at that, you could try a million versions of that. You might find one that was better, and then, you know, repeat. And so the concern is that you get some sort of runaway effect where everything is fine on Thursday evening, and you come back into the lab on Friday morning, and because of the speed of computers and so forth, things have gone crazy, and suddenly --  14:45\nST: I would say this is a possibility, but it's a very remote possibility. So let me just translate what I heard you say. In the AlphaGo case, we had exactly this thing: the computer would play the game against itself and then learn new rules. And what machine learning is is a rewriting of the rules. It's the rewriting of code. But I think there was absolutely no concern that AlphaGo would take over the world. It can't even play chess.  15:11\nCA: No, no, no, but now, these are all very single-domain things. But it's possible to imagine. I mean, we just saw a computer that seemed nearly capable of passing a university entrance test, that can kind of -- it can't read and understand in the sense that we can, but it can certainly absorb all the text and maybe see increased patterns of meaning. Isn't there a chance that, as this broadens out, there could be a different kind of runaway effect?  15:39\nST: That's where I draw the line, honestly. And the chance exists -- I don't want to downplay it -- but I think it's remote, and it's not the thing that's on my mind these days, because I think the big revolution is something else. Everything successful in AI to the present date has been extremely specialized, and it's been thriving on a single idea, which is massive amounts of data. The reason AlphaGo works so well is because of massive numbers of Go plays, and AlphaGo can't drive a car or fly a plane. The Google self-driving car or the Udacity self-driving car thrives on massive amounts of data, and it can't do anything else. It can't even control a motorcycle. It's a very specific, domain-specific function, and the same is true for our cancer app. There has been almost no progress on this thing called \"general AI,\" where you go to an AI and say, \"Hey, invent for me special relativity or string theory.\" It's totally in the infancy.  16:32\nThe reason I want to emphasize this, I see the concerns, and I want to acknowledge them. But if I were to think about one thing, I would ask myself the question, \"What if we can take anything repetitive and make ourselves 100 times as efficient?\" It so turns out, 300 years ago, we all worked in agriculture and did farming and did repetitive things. Today, 75 percent of us work in offices and do repetitive things. We've become spreadsheet monkeys. And not just low-end labor. We've become dermatologists doing repetitive things, lawyers doing repetitive things. I think we are at the brink of being able to take an AI, look over our shoulders, and they make us maybe 10 or 50 times as effective in these repetitive things. That's what is on my mind.  17:22\nCA: That sounds super exciting. The process of getting there seems a little terrifying to some people, because once a computer can do this repetitive thing much better than the dermatologist or than the driver, especially, is the thing that's talked about so much now, suddenly millions of jobs go, and, you know, the country's in revolution before we ever get to the more glorious aspects of what's possible.  17:48\nST: Yeah, and that's an issue, and it's a big issue, and it was pointed out yesterday morning by several guest speakers. Now, prior to me showing up onstage, I confessed I'm a positive, optimistic person, so let me give you an optimistic pitch, which is, think of yourself back 300 years ago. Europe just survived 140 years of continuous war, none of you could read or write, there were no jobs that you hold today, like investment banker or software engineer or TV anchor. We would all be in the fields and farming. Now here comes little Sebastian with a little steam engine in his pocket, saying, \"Hey guys, look at this. It's going to make you 100 times as strong, so you can do something else.\" And then back in the day, there was no real stage, but Chris and I hang out with the cows in the stable, and he says, \"I'm really concerned about it, because I milk my cow every day, and what if the machine does this for me?\"  18:43\nThe reason why I mention this is, we're always good in acknowledging past progress and the benefit of it, like our iPhones or our planes or electricity or medical supply. We all love to live to 80, which was impossible 300 years ago. But we kind of don't apply the same rules to the future. So if I look at my own job as a CEO, I would say 90 percent of my work is repetitive, I don't enjoy it, I spend about four hours per day on stupid, repetitive email. And I'm burning to have something that helps me get rid of this. Why? Because I believe all of us are insanely creative; I think the TED community more than anybody else. But even blue-collar workers; I think you can go to your hotel maid and have a drink with him or her, and an hour later, you find a creative idea. What this will empower is to turn this creativity into action. Like, what if you could build Google in a day? What if you could sit over beer and invent the next Snapchat, whatever it is, and tomorrow morning it's up and running?  19:49\nAnd that is not science fiction. What's going to happen is, we are already in history. We've unleashed this amazing creativity by de-slaving us from farming and later, of course, from factory work and have invented so many things. It's going to be even better, in my opinion. And there's going to be great side effects. One of the side effects will be that things like food and medical supply and education and shelter and transportation will all become much more affordable to all of us, not just the rich people.  20:22\nCA: Hmm. So when Martin Ford argued, you know, that this time it's different because the intelligence that we've used in the past to find new ways to be will be matched at the same pace by computers taking over those things, what I hear you saying is that, not completely, because of human creativity. Do you think that that's fundamentally different from the kind of creativity that computers can do?  20:50\nST: So, that's my firm belief as an AI person -- that I haven't seen any real progress on creativity and out-of-the-box thinking. What I see right now -- and this is really important for people to realize, because the word \"artificial intelligence\" is so threatening, and then we have Steve Spielberg tossing a movie in, where all of a sudden the computer is our overlord, but it's really a technology. It's a technology that helps us do repetitive things. And the progress has been entirely on the repetitive end. It's been in legal document discovery. It's been contract drafting. It's been screening X-rays of your chest. And these things are so specialized, I don't see the big threat of humanity. In fact, we as people -- I mean, let's face it: we've become superhuman. We've made us superhuman. We can swim across the Atlantic in 11 hours. We can take a device out of our pocket and shout all the way to Australia, and in real time, have that person shouting back to us. That's physically not possible. We're breaking the rules of physics. When this is said and done, we're going to remember everything we've ever said and seen, you'll remember every person, which is good for me in my early stages of Alzheimer's. Sorry, what was I saying? I forgot.  22:02\nCA: (Laughs)  22:03\nST: We will probably have an IQ of 1,000 or more. There will be no more spelling classes for our kids, because there's no spelling issue anymore. There's no math issue anymore. And I think what really will happen is that we can be super creative. And we are. We are creative. That's our secret weapon.  22:21\nCA: So the jobs that are getting lost, in a way, even though it's going to be painful, humans are capable of more than those jobs. This is the dream. The dream is that humans can rise to just a new level of empowerment and discovery. That's the dream.  22:36\nST: And think about this: if you look at the history of humanity, that might be whatever -- 60-100,000 years old, give or take -- almost everything that you cherish in terms of invention, of technology, of things we've built, has been invented in the last 150 years. If you toss in the book and the wheel, it's a little bit older. Or the axe. But your phone, your sneakers, these chairs, modern manufacturing, penicillin -- the things we cherish. Now, that to me means the next 150 years will find more things. In fact, the pace of invention has gone up, not gone down, in my opinion. I believe only one percent of interesting things have been invented yet. Right? We haven't cured cancer. We don't have flying cars -- yet. Hopefully, I'll change this. That used to be an example people laughed about. (Laughs) It's funny, isn't it? Working secretly on flying cars. We don't live twice as long yet. OK? We don't have this magic implant in our brain that gives us the information we want. And you might be appalled by it, but I promise you, once you have it, you'll love it. I hope you will. It's a bit scary, I know.  23:48\nThere are so many things we haven't invented yet that I think we'll invent. We have no gravity shields. We can't beam ourselves from one location to another. That sounds ridiculous, but about 200 years ago, experts were of the opinion that flight wouldn't exist, even 120 years ago, and if you moved faster than you could run, you would instantly die. So who says we are correct today that you can't beam a person from here to Mars?  24:12\nCA: Sebastian, thank you so much for your incredibly inspiring vision and your brilliance. Thank you, Sebastian Thrun. That was fantastic. (Applause)",
            "title": "Transcript"
        },
        {
            "location": "/2018/06/#excerpt_2",
            "text": "1.",
            "title": "Excerpt"
        },
        {
            "location": "/2018/06/#phrases",
            "text": "on and off: intermittently, from time to time, now and again, e.g., it rained on and off most of the afternoon.    intermittently: in an way that starts and stops often over a period of time; not regularly, e.g., Protests continued intermittently throughout November.",
            "title": "Phrases"
        }
    ]
}